{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe69520-de18-4f7e-a57d-3ce1bf9c801d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bf477c-4d95-43c1-98b3-b204326365e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780a1904-2987-455f-90ef-5de906bf8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.types import DoubleType\n",
    "import time\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efbb38-8ac2-4704-a8d2-c5bf884b37b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0d7bb0-bb83-4dd1-bc10-c99a76b7af12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/27 16:52:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"spark://spark-master:7077\").appName(\"ManualQRDecomposition\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc8cf8-3584-4cdf-88fa-7a3dbd17c89a",
   "metadata": {},
   "source": [
    "# 1) Funktionen für Lineare Regression mit QR Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd80614-6695-401e-a843-8b9e585e4f28",
   "metadata": {},
   "source": [
    "## 1.1) Lösen eines LGS durch Rückwärts Einsetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52d27f0-21af-4b08-ad87-c39f37e81e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_substitution(R, b):\n",
    "    \"\"\"\n",
    "    Solves the upper triangular system Ax = y for x using backward substitution.\n",
    "    \n",
    "    Args:\n",
    "    R: Upper triangular matrix\n",
    "    y (array): The right-hand side vector.\n",
    "    \n",
    "    Returns:\n",
    "    array: Solution vector b.\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    x = np.zeros(n)\n",
    "    \n",
    "    for i in range(n-1, -1, -1):\n",
    "        sum_val = 0\n",
    "        for j in range(i+1, n):\n",
    "            sum_val += R[i, j] * x[j]\n",
    "        \n",
    "        if abs(R[i, i]) > 1e-10:  # Check for numerical stability\n",
    "            x[i] = (b[i] - sum_val) / R[i, i]\n",
    "        else:\n",
    "            x[i] = 0\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699aa431-e57f-42a3-b539-20c118e38599",
   "metadata": {},
   "source": [
    "## 1.2) QR Zerlegung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60304a-4ec6-4928-989b-1d4a5c8cb70c",
   "metadata": {},
   "source": [
    "### 1.2.1) Gram Schmidt ohne Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc07ed62-e4b1-42aa-99fd-0f649fc8b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_qr_decomposition(X_array):\n",
    "    \"\"\"\n",
    "    Manual implementation of QR decomposition using Gram-Schmidt process.\n",
    "    \n",
    "    Args:\n",
    "        X_array: Input matrix as numpy array\n",
    "        \n",
    "    Returns:\n",
    "        Q: Orthogonal matrix\n",
    "        R: Upper triangular matrix\n",
    "    \"\"\"\n",
    "    n, m = X_array.shape\n",
    "    Q = np.zeros((n, m))\n",
    "    R = np.zeros((m, m))\n",
    "    \n",
    "    for j in range(m):\n",
    "        v = X_array[:, j].copy()\n",
    "        \n",
    "        for i in range(j):\n",
    "            R[i, j] = 0\n",
    "            for k in range(n):\n",
    "                R[i, j] += Q[k, i] * X_array[k, j]\n",
    "            \n",
    "            for k in range(n):\n",
    "                v[k] = v[k] - R[i, j] * Q[k, i]\n",
    "        \n",
    "        norm = 0\n",
    "        for k in range(n):\n",
    "            norm += v[k] * v[k]\n",
    "        norm = np.sqrt(norm)\n",
    "        \n",
    "        R[j, j] = norm\n",
    "        \n",
    "        if norm > 1e-10:  # Avoid division by very small numbers\n",
    "            for k in range(n):\n",
    "                Q[k, j] = v[k] / norm\n",
    "        else:\n",
    "            for k in range(n):\n",
    "                Q[k, j] = 0\n",
    "    \n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515461cc-cc5e-4bec-b04a-7d90294d8f71",
   "metadata": {},
   "source": [
    "### 1.2.1) Gram Schmidt mit Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8830863b-6f7b-4317-b0e6-bc25d95d1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt(X_df):\n",
    "    X_rdd = X_df.rdd.cache()\n",
    "    m = len(X_df.first().features)\n",
    "    Q = []\n",
    "    R = np.zeros((m, m))\n",
    "\n",
    "    for j in range(m):\n",
    "        v = X_rdd.map(lambda row: row.features[j]).collect()\n",
    "        \n",
    "        for i in range(j):\n",
    "            R[i, j] = np.dot(Q[i], v)\n",
    "            v -= R[i, j] * Q[i]\n",
    "\n",
    "        R[j, j] = np.linalg.norm(v)\n",
    "        Q.append(v / R[j, j])\n",
    "    \n",
    "    R_dict = {i: R[i, :] for i in range(m)}\n",
    "\n",
    "    Q_df = spark.createDataFrame([Row(features=DenseVector(q)) for q in zip(*Q)])\n",
    "\n",
    "    return Q_df, R_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b829778-5e93-476e-8c5e-2b93dee3beab",
   "metadata": {},
   "source": [
    "## 1.3) Datensatz simulieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8df7af-e5c3-4194-b54b-64bdaa2b25ff",
   "metadata": {},
   "source": [
    "### 1.3.1) Datensatz simulieren ohne Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98535df-d721-4911-bb4b-1dab272760d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_numpy(n, p, beta_true):\n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(n, p)\n",
    "    X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "    y = X @ beta_true + np.random.randn(n) * 0.1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3053fff-9fd2-4383-b210-efd0a70ca89e",
   "metadata": {},
   "source": [
    "### 1.3.2) Datensatz simulieren mit Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0d5d5e-a431-4674-8e25-fadb4a65e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_spark(n_samples, n_features, beta_true, noise_std=0.1, partition_size=10000):\n",
    "    \"\"\"\n",
    "    Generates synthetic data optimized for distributed processing.\n",
    "    \n",
    "    Args:\n",
    "        spark: SparkSession\n",
    "        n: Number of observations\n",
    "        p: Number of features\n",
    "        beta_true: True coefficients\n",
    "        num_partitions: Number of partitions for distributed data\n",
    "    \"\"\"\n",
    "    def generate_partition(partition_size):\n",
    "        X = np.random.randn(partition_size, n_features)\n",
    "        X = np.column_stack([np.ones(partition_size), X])\n",
    "        y = X @ beta_true + np.random.normal(0, noise_std, partition_size)\n",
    "        return [(Vectors.dense(x), float(y_i)) for x, y_i in zip(X, y)]\n",
    "    \n",
    "    num_partitions = max(n_samples // partition_size, spark.sparkContext.defaultParallelism)\n",
    "    samples_per_partition = n_samples // num_partitions\n",
    "    \n",
    "    rdd = (spark.sparkContext\n",
    "           .parallelize(range(num_partitions), num_partitions)\n",
    "           .flatMap(lambda _: generate_partition(samples_per_partition)))\n",
    "    \n",
    "    return spark.createDataFrame(rdd, [\"features\", \"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d14c3-ea1f-4d92-8823-f39e6ecc1023",
   "metadata": {},
   "source": [
    "## 1.4) Funktion zur Durchführung der linearen Regression \n",
    "\n",
    "- simuliert einen Datensatz\n",
    "- führt die lineare Regression durch\n",
    "- berechnet alle Metriken, die auch statmodels `summary()` ausgibt\n",
    "- misst die Zeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6acd3-d231-4ac8-bd3f-7c28c9dd525b",
   "metadata": {},
   "source": [
    "### 1.4.1) Funktion zur Berechnung der Statistik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d058ac9-6aeb-4537-a3a9-b916d74b259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(X, y, beta, residuals):\n",
    "    n, k = X.shape\n",
    "    SSE = np.sum(residuals ** 2)\n",
    "    SST = np.sum((y - np.mean(y)) ** 2)\n",
    "    SSR = SST - SSE\n",
    "    df_residuals = n - k\n",
    "    df_model = k - 1\n",
    "    \n",
    "    r_squared = 1 - (SSE / SST)\n",
    "    adj_r_squared = 1 - ((1 - r_squared) * (n - 1) / df_residuals)\n",
    "    \n",
    "    MSE = SSE / df_residuals\n",
    "    MSR = SSR / df_model\n",
    "    f_statistic = MSR / MSE\n",
    "    f_p_value = stats.f.sf(f_statistic, df_model, df_residuals)\n",
    "    \n",
    "    sigma_squared = MSE\n",
    "    XtX_inv = np.linalg.inv(X.T @ X)\n",
    "    se = np.sqrt(np.diag(sigma_squared * XtX_inv))\n",
    "    t_values = beta / se\n",
    "    p_values = 2 * (1 - stats.t.cdf(np.abs(t_values), df_residuals))\n",
    "    \n",
    "    skewness = stats.skew(residuals)\n",
    "    kurtosis = stats.kurtosis(residuals, fisher=False)\n",
    "    log_likelihood = -0.5 * n * (np.log(2 * np.pi * sigma_squared) + 1)\n",
    "    AIC = 2 * k - 2 * log_likelihood\n",
    "    BIC = n * np.log(SSE / n) + k * np.log(n)\n",
    "    \n",
    "    dw_statistic = np.sum(np.diff(residuals) ** 2) / SSE\n",
    "    \n",
    "    jarque_bera_stat = (n / 6) * (skewness**2 + (kurtosis - 3)**2 / 4)\n",
    "    prob_jb = 1 - stats.chi2.cdf(jarque_bera_stat, df=2)\n",
    "    \n",
    "    return {\n",
    "        'r_squared': r_squared,\n",
    "        'Adjusted R-squared': adj_r_squared,\n",
    "        'F-statistic': f_statistic,\n",
    "        'Prob (F-statistic)': f_p_value,\n",
    "        'Log-Likelihood': log_likelihood,\n",
    "        'AIC': AIC,\n",
    "        'BIC': BIC,\n",
    "        'coef': beta,\n",
    "        'std err': se,\n",
    "        't': t_values,\n",
    "        'P>|t|': p_values,\n",
    "        'Skew': skewness,\n",
    "        'Kurtosis': kurtosis,\n",
    "        'Durbin-Watson': dw_statistic,\n",
    "        'Jarque-Bera (JB)': jarque_bera_stat,\n",
    "        'Prob(JB)': prob_jb\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ea64d-6edc-4b37-9ff9-ede937bf1939",
   "metadata": {},
   "source": [
    "### 1.4.1 Lineare Regression ohne Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15e67860-c100-450b-a82a-8147fc35694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_manual_qr(X, y):\n",
    "    start_time = time.time()\n",
    "    Q, R = manual_qr_decomposition(X)\n",
    "    beta = backward_substitution(R, Q.T @ y)\n",
    "\n",
    "    y_pred = np.dot(X, beta) # mit den durch QR berechneten Betas die vorhergesagten y-Werte des linReg Modells bestimmen\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    result = compute_statistics(X, y, beta, residuals)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    return result, elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f46832-388d-431c-94e7-7158f2545563",
   "metadata": {},
   "source": [
    "### 1.4.2 Optimiert für Spark mit manueller QR Zerlegung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9e0c2d7-c257-47ee-a9f1-8e185dbdac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ols_manual(df):\n",
    "    \"\"\"\n",
    "    Fit OLS using manual QR decomposition and backward substitution, with extended statistics.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Calculate combined QR decomposition across partitions\n",
    "    def process_partition(iterator):\n",
    "        # Local arrays for QR decomposition\n",
    "        X_local = []\n",
    "        y_local = []\n",
    "        for row in iterator:\n",
    "            X_local.append(row.features.toArray())\n",
    "            y_local.append(row.y)\n",
    "        \n",
    "        # Early exit if partition is empty\n",
    "        if not X_local:\n",
    "            return []\n",
    "        \n",
    "        X_local = np.vstack(X_local)\n",
    "        y_local = np.array(y_local)\n",
    "        \n",
    "        # Perform local QR decomposition\n",
    "        Q_local, R_local = manual_qr_decomposition(X_local)\n",
    "        \n",
    "        # Calculate local Q^T y\n",
    "        Qty_local = np.dot(Q_local.T, y_local)\n",
    "        \n",
    "        return [(R_local, Qty_local)]\n",
    "    \n",
    "    # Aggregate QR decomposition results\n",
    "    results = df.rdd.mapPartitions(process_partition).reduce(lambda a, b: (\n",
    "        a[0] + b[0],  # Sum R matrices\n",
    "        a[1] + b[1]   # Sum Q^T y vectors\n",
    "    ))\n",
    "    \n",
    "    R_total, Qty_total = results\n",
    "    \n",
    "    # Step 2: Solve for beta using the aggregated QR components\n",
    "    beta = backward_substitution(R_total, Qty_total)\n",
    "    \n",
    "    # Step 3: Prepare full dataset X and y to compute statistics\n",
    "    X = np.vstack([row.features.toArray() for row in df.collect()])\n",
    "    y = np.array([row.y for row in df.collect()])\n",
    "    y_pred = X.dot(beta)\n",
    "    residuals = y - y_pred\n",
    "    \n",
    "    # Compute extended statistics using the unified function\n",
    "    stats = compute_statistics(X, y, beta, residuals)\n",
    "    \n",
    "    computation_time = time.time() - start_time\n",
    "    stats['computation_time'] = computation_time\n",
    "    stats['n_samples'] = len(y)\n",
    "    stats['n_features'] = X.shape[1]\n",
    "    \n",
    "    return beta, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f984c5e9-2db4-4409-9fdb-7985c8c525d1",
   "metadata": {},
   "source": [
    "### Optimiert für Spark mit Built-In Functions für die QR Zerlegung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1651dd-4214-4996-b8d9-5fce20fada03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ols_spark(df):\n",
    "    \"\"\"\n",
    "    Fit an OLS model using Spark's built-in LinearRegression model, which uses QR decomposition.\n",
    "    \n",
    "    Args:\n",
    "        df: Spark DataFrame with features and target variable.\n",
    "    \n",
    "    Returns:\n",
    "        model: Fitted linear regression model\n",
    "        training_summary: Summary of training metrics\n",
    "    \"\"\"\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"y\", solver=\"normal\")\n",
    "    model = lr.fit(df)\n",
    "    \n",
    "    # Get the training summary to extract information like R^2, RMSE, etc.\n",
    "    training_summary = model.summary\n",
    "    \n",
    "    return model, training_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4560b59-a830-4be4-a0ab-814ae0cdd1ba",
   "metadata": {},
   "source": [
    "## 1.5) Funktion für Durchführung des Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a3f13-0fb2-494f-98d2-137e5fa557bc",
   "metadata": {},
   "source": [
    "### Berechnung für Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67f44301-7434-41a8-bebe-410ba1b9ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark_numpy(n_list, beta_true, p, repetitions=10):\n",
    "    results = []\n",
    "\n",
    "    for n in n_list:\n",
    "        times = []\n",
    "        for _ in range(repetitions):\n",
    "            X, y = create_data_numpy(n, p, beta_true)\n",
    "            beta, elapsed_time = linear_regression_manual_qr(X, y)\n",
    "            times.append(elapsed_time)\n",
    "\n",
    "        avg_time = np.mean(times)\n",
    "        std_time = np.std(times)\n",
    "        results.append([n, avg_time, std_time])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c2e2ba-9e63-4d63-8115-0fe80afacb22",
   "metadata": {},
   "source": [
    "### Berechnung für eine Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31b19a49-c538-4f47-ac43-4234871356e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_benchmark_range(max_n, p, beta_true, step_size=100000, repetitions=10):\n",
    "    \"\"\"Run benchmarking with fixed step size increments.\"\"\"\n",
    "    #n_values = np.arange(step_size, max_n + step_size, step_size, dtype=int)\n",
    "    n_values = np.logspace(5, np.log10(max_n), 5, dtype=int)\n",
    "    results = []\n",
    "    \n",
    "    for n in n_values:\n",
    "        times = []\n",
    "        r_squares = []\n",
    "        successful_runs = 0\n",
    "        \n",
    "        print(f\"\\nBenchmarking n={n:,} samples...\")\n",
    "        \n",
    "        for i in range(repetitions):\n",
    "            try:\n",
    "                df = create_data_spark(n, p, beta_true)\n",
    "                start_time = time.time()\n",
    "                beta, summary = fit_ols_manual(df)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                \n",
    "                times.append(elapsed_time)\n",
    "                r_squares.append(summary['r_squared'])\n",
    "                successful_runs += 1\n",
    "                \n",
    "                print(f\"  Run {i+1}: time={elapsed_time:.2f}s, R²={summary['r_squared']:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Run {i+1} failed: {str(e)}\")\n",
    "        \n",
    "        if successful_runs > 0:\n",
    "            result = {\n",
    "                'n_samples': n,\n",
    "                'n_features': p,\n",
    "                'mean_time': np.mean(times),\n",
    "                'std_time': np.std(times),\n",
    "                'mean_r_squared': np.mean(r_squares),\n",
    "                'std_r_squared': np.std(r_squares),\n",
    "                'successful_runs': successful_runs\n",
    "            }\n",
    "            results.append(result)\n",
    "            6\n",
    "            print(f\"\\nSummary for n={n:,}:\")\n",
    "            print(f\"  Mean time: {result['mean_time']:.2f}s ± {result['std_time']:.2f}s\")\n",
    "            print(f\"  Mean R²: {result['mean_r_squared']:.4f} ± {result['std_r_squared']:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee49a82-d6f0-4301-a20e-3f03407be25a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Berechnung für einen festen Wert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4726dfbf-79ed-4be7-87ca-222d8aaa810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_benchmark_point(n, p, beta_true, repetitions=10):\n",
    "    \"\"\"Run benchmarking for a single sample size n.\"\"\"\n",
    "    results = []\n",
    "    times = []\n",
    "    r_squares = []\n",
    "    successful_runs = 0\n",
    "    \n",
    "    print(f\"\\nBenchmarking n={n:,} samples...\")\n",
    "    \n",
    "    for i in range(repetitions):\n",
    "        try:\n",
    "            df = create_data_spark(n, p, beta_true)\n",
    "            start_time = time.time()\n",
    "            beta, summary = fit_ols_manual(df)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            times.append(elapsed_time)\n",
    "            r_squares.append(summary['r_squared'])\n",
    "            successful_runs += 1\n",
    "            \n",
    "            print(f\"  Run {i+1}: time={elapsed_time:.2f}s, R²={summary['r_squared']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Run {i+1} failed: {str(e)}\")\n",
    "    \n",
    "    if successful_runs > 0:\n",
    "        result = {\n",
    "            'n_samples': n,\n",
    "            'n_features': p,\n",
    "            'mean_time': np.mean(times),\n",
    "            'std_time': np.std(times),\n",
    "            'mean_r_squared': np.mean(r_squares),\n",
    "            'std_r_squared': np.std(r_squares),\n",
    "            'successful_runs': successful_runs\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"\\nSummary for n={n:,}:\")\n",
    "        print(f\"  Mean time: {result['mean_time']:.2f}s ± {result['std_time']:.2f}s\")\n",
    "        print(f\"  Mean R²: {result['mean_r_squared']:.4f} ± {result['std_r_squared']:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3424ab2-16f9-4cf1-a321-fe79f93a2e96",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Berechnung für Spark Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46854dfe-34a2-4a13-9ce3-e37e71d9c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark_spark(max_n, p, beta_true, repetitions=10):\n",
    "    \"\"\"\n",
    "    Run benchmarking for the OLS regression with different sample sizes.\n",
    "    \n",
    "    Args:\n",
    "        max_n: Maximum number of samples\n",
    "        p: Number of features\n",
    "        beta_true: True coefficient values for the data generation\n",
    "        repetitions: Number of repetitions for each sample size\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Benchmarking results as Pandas DataFrame\n",
    "    \"\"\"\n",
    "    n_values = np.linspace(100000, max_n, 10, dtype=int)  # Minimum of 10 different sample sizes\n",
    "    results = []\n",
    "\n",
    "    for n in n_values:\n",
    "        times = []\n",
    "        for _ in range(repetitions):\n",
    "            df = generate_synthetic_data(n, p, beta_true)\n",
    "            start_time = time.time()\n",
    "            model, summary = fit_ols_spark(df)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            times.append(elapsed_time)\n",
    "\n",
    "        avg_time = np.mean(times)\n",
    "        std_time = np.std(times)\n",
    "        results.append({\n",
    "            'n_samples': n,\n",
    "            'n_features': p,\n",
    "            'mean_time': avg_time,\n",
    "            'std_time': std_time,\n",
    "            'r_squared': summary.r2,\n",
    "            'adj_r_squared': summary.r2adj\n",
    "        })\n",
    "\n",
    "        print(f\"Benchmark for n={n}: mean_time={avg_time:.4f}s, std_time={std_time:.4f}s, R^2={summary.r2:.4f}\")\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f3e295-03cd-479b-aefc-eb1e577872f8",
   "metadata": {},
   "source": [
    "# 2) Durchführung des Benchmarks und Ausgeben der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09235d19-d83b-489f-8b37-c6069fa456bc",
   "metadata": {},
   "source": [
    "## 2.1) Durchführung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca3874e2-0a3d-4276-a57c-db966351ea4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[1;32m      3\u001b[0m beta_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(n_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m results_numpy \u001b[38;5;241m=\u001b[39m \u001b[43mrun_benchmark_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mrun_benchmark_numpy\u001b[0;34m(n_list, beta_true, p, repetitions)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repetitions):\n\u001b[1;32m      7\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m create_data_numpy(n, p, beta_true)\n\u001b[0;32m----> 8\u001b[0m     beta, elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_regression_manual_qr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     times\u001b[38;5;241m.\u001b[39mappend(elapsed_time)\n\u001b[1;32m     11\u001b[0m avg_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(times)\n",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m, in \u001b[0;36mlinear_regression_manual_qr\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlinear_regression_manual_qr\u001b[39m(X, y):\n\u001b[1;32m      2\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m     Q, R \u001b[38;5;241m=\u001b[39m \u001b[43mmanual_qr_decomposition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     beta \u001b[38;5;241m=\u001b[39m backward_substitution(R, Q\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m y)\n\u001b[1;32m      6\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X, beta) \u001b[38;5;66;03m# mit den durch QR berechneten Betas die vorhergesagten y-Werte des linReg Modells bestimmen\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m, in \u001b[0;36mmanual_qr_decomposition\u001b[0;34m(X_array)\u001b[0m\n\u001b[1;32m     20\u001b[0m R[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m---> 22\u001b[0m     R[i, j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Q[k, i] \u001b[38;5;241m*\u001b[39m X_array[k, j]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m     25\u001b[0m     v[k] \u001b[38;5;241m=\u001b[39m v[k] \u001b[38;5;241m-\u001b[39m R[i, j] \u001b[38;5;241m*\u001b[39m Q[k, i]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_values = [200000, 500000, 1000000, 5000000, 10000000]\n",
    "n_features = 7\n",
    "beta_true = np.random.randn(n_features + 1)\n",
    "results_numpy = run_benchmark_numpy(n_list=n_values, beta_true=beta_true, p=n_features) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26997485-2f3b-4dd1-95cc-5efb1c860c6a",
   "metadata": {},
   "source": [
    "### Benchmark Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de869ab9-65a4-4416-950d-aa99543a5bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking n=1,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 1: time=5.74s, R²=-1.0447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 2: time=1.96s, R²=-1.0613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 3: time=1.74s, R²=-1.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 4: time=1.76s, R²=-1.1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 5: time=1.67s, R²=-1.2264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 6: time=1.54s, R²=-1.0896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 7: time=1.71s, R²=-1.0860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 8: time=1.62s, R²=-1.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 9: time=1.54s, R²=-1.0442\n",
      "  Run 10: time=1.65s, R²=-1.1579\n",
      "\n",
      "Summary for n=1,000:\n",
      "  Mean time: 2.09s ± 1.22s\n",
      "  Mean R²: -1.0880 ± 0.0613\n"
     ]
    }
   ],
   "source": [
    "n_features = 7\n",
    "beta_true = np.random.randn(n_features + 1)  # +1 for intercept\n",
    "results_point = run_benchmark_point(n=1000, p=n_features, beta_true=beta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c839840-0386-48fb-bfdc-5a6900954528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>std_time</th>\n",
       "      <th>mean_r_squared</th>\n",
       "      <th>std_r_squared</th>\n",
       "      <th>successful_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>7</td>\n",
       "      <td>2.093461</td>\n",
       "      <td>1.221278</td>\n",
       "      <td>-1.087952</td>\n",
       "      <td>0.061319</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_samples  n_features  mean_time  std_time  mean_r_squared  std_r_squared  \\\n",
       "0       1000           7   2.093461  1.221278       -1.087952       0.061319   \n",
       "\n",
       "   successful_runs  \n",
       "0               10  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2758cc14-daf0-4cb1-ba29-dce8c9be3059",
   "metadata": {},
   "source": [
    "### Benchmark Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57930b16-9358-40f4-9b00-6afc3fadd71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking n=100,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 1: time=7.32s, R²=-0.9896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 2: time=5.28s, R²=-0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 3: time=5.41s, R²=-0.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 4: time=5.10s, R²=-0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 5: time=5.33s, R²=-0.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 6: time=5.25s, R²=-1.0021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 7: time=5.26s, R²=-0.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 8: time=5.44s, R²=-0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 9: time=5.25s, R²=-0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 10: time=5.69s, R²=-0.9971\n",
      "\n",
      "Summary for n=100,000:\n",
      "  Mean time: 5.53s ± 0.61s\n",
      "  Mean R²: -0.9953 ± 0.0041\n",
      "\n",
      "Benchmarking n=31,622 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 1: time=2.79s, R²=-0.9719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 2: time=2.80s, R²=-0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 3: time=2.73s, R²=-1.0221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 4: time=2.75s, R²=-1.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 5: time=2.72s, R²=-1.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 6: time=2.62s, R²=-1.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 7: time=2.77s, R²=-1.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 8: time=2.67s, R²=-0.9752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 9: time=2.74s, R²=-0.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 10: time=2.62s, R²=-1.0089\n",
      "\n",
      "Summary for n=31,622:\n",
      "  Mean time: 2.72s ± 0.06s\n",
      "  Mean R²: -1.0010 ± 0.0167\n",
      "\n",
      "Benchmarking n=10,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 1: time=1.89s, R²=-1.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 2: time=1.94s, R²=-0.9135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 3: time=1.89s, R²=-0.9456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 4: time=1.84s, R²=-1.0290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 5: time=2.02s, R²=-1.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 6: time=1.90s, R²=-0.9678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 7: time=1.89s, R²=-1.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 8: time=1.82s, R²=-1.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 9: time=1.86s, R²=-1.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 10: time=1.93s, R²=-1.0094\n",
      "\n",
      "Summary for n=10,000:\n",
      "  Mean time: 1.90s ± 0.05s\n",
      "  Mean R²: -0.9917 ± 0.0351\n",
      "\n",
      "Benchmarking n=3,162 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 1: time=1.61s, R²=-0.8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 2: time=1.65s, R²=-0.9527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 3: time=1.87s, R²=-1.1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 4: time=1.65s, R²=-0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 5: time=1.71s, R²=-0.9460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 6: time=1.70s, R²=-0.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 7: time=1.77s, R²=-1.0353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 8: time=1.74s, R²=-1.0395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 9: time=1.61s, R²=-0.9521\n",
      "  Run 10: time=1.67s, R²=-1.0427\n",
      "\n",
      "Summary for n=3,162:\n",
      "  Mean time: 1.70s ± 0.07s\n",
      "  Mean R²: -0.9952 ± 0.0625\n",
      "\n",
      "Benchmarking n=1,000 samples...\n",
      "  Run 1: time=1.49s, R²=-0.9748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 2: time=1.48s, R²=-1.1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 3: time=1.55s, R²=-0.8807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 4: time=1.55s, R²=-1.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 5: time=1.56s, R²=-1.1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 6: time=1.62s, R²=-1.0539\n",
      "  Run 7: time=1.61s, R²=-0.7653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 8: time=1.68s, R²=-0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 9: time=1.61s, R²=-1.1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 10: time=1.61s, R²=-1.0543\n",
      "\n",
      "Summary for n=1,000:\n",
      "  Mean time: 1.58s ± 0.06s\n",
      "  Mean R²: -1.0033 ± 0.1243\n"
     ]
    }
   ],
   "source": [
    "n_features = 7\n",
    "beta_true = np.random.randn(n_features + 1)  # +1 for intercept\n",
    "results_range = run_benchmark_range(max_n=1000, p=n_features, beta_true=beta_true, step_size=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38eab9-100f-40ec-86c3-3ec84a177118",
   "metadata": {},
   "source": [
    "### Benchmark Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ea3fb-b1e3-4230-8a12-45293bcdf20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n = 10000000\n",
    "n_features = 7\n",
    "beta_true = np.random.randn(n_features + 1)\n",
    "results_spark = run_benchmark_spark(max_n, n_features, beta_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ba8cd-e4cd-43f1-ae36-a039696ce95a",
   "metadata": {},
   "source": [
    "## 2.2) Ausgeben der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5688e6e-9dfa-4ce8-903e-01d61b598899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_info(dataframes):\n",
    "    # Erstellen einer Liste, um die extrahierten Daten zu sammeln\n",
    "    extracted_data = []\n",
    "    \n",
    "    # Durchlaufen aller DataFrames in der Liste\n",
    "    for df in dataframes:\n",
    "        # Überprüfen, ob die benötigten Spalten im DataFrame vorhanden sind\n",
    "        if all(col in df.columns for col in ['n_samples', 'n_features', 'mean_time']):\n",
    "            # Extrahieren der benötigten Daten und Hinzufügen zur Liste\n",
    "            extracted_data.append(df[['n_samples', 'n_features', 'mean_time']])\n",
    "        else:\n",
    "            # Falls nicht alle Spalten vorhanden sind, fügen wir eine Fehlermeldung hinzu\n",
    "            extracted_data.append(pd.DataFrame({'Error': ['Missing columns']}))\n",
    "    \n",
    "    # Kombinieren aller Daten in einem DataFrame\n",
    "    result = pd.concat(extracted_data, ignore_index=True)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c0e1f5e-2563-48cc-afc7-fe9b05c7c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_samples  n_features  mean_time\n",
      "0       1000           7   2.093461\n",
      "1     100000           7   5.533020\n",
      "2      31622           7   2.720579\n",
      "3      10000           7   1.897306\n",
      "4       3162           7   1.697407\n",
      "5       1000           7   1.575247\n"
     ]
    }
   ],
   "source": [
    "result_df = extract_info([results_numpy, results_range])\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95411dc-0d37-4c21-a623-d08fb9c92c0e",
   "metadata": {},
   "source": [
    "- bei n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b5098-64e9-4e05-956a-0605c8884113",
   "metadata": {},
   "source": [
    "## 2.3) Plotten der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a3738-4d09-4794-95fd-7edeb2bebeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_benchmark_results(n_values, avg_times, std_times):\n",
    "    \"\"\"\n",
    "    Plots benchmark results as error bars without connecting lines.\n",
    "\n",
    "    Parameters:\n",
    "    n_values (list): List of sample sizes (number of observations).\n",
    "    avg_times (list): List of average computation times for each sample size.\n",
    "    std_times (list): List of standard deviations of the computation times for each sample size.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.errorbar(n_values, avg_times, yerr=std_times, fmt='o', ecolor='r', capsize=5,\n",
    "                 label='Durchschnittliche Rechenzeit mit Standardabweichung', linestyle='None')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Anzahl der Beobachtungen (n)')\n",
    "    plt.ylabel('Rechenzeit (s)')\n",
    "    plt.title('Rechenzeit der QR-Dekompositions-basierten Regression für wachsendes n')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca867fd1-e441-4327-863a-0dfaad6e7ad9",
   "metadata": {},
   "source": [
    "### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9c3fa-3f29-4d98-b398-e1fdde5522b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_benchmark_results(n_values, avg_times, std_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b3849-98ab-49e3-b977-547495748bd6",
   "metadata": {},
   "source": [
    "### Spark manuell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fa1bc-042c-4638-aded-7d5748f7bb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45e2983f-d60e-4493-b2c7-666cba684af8",
   "metadata": {},
   "source": [
    "### Spark normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30124dce-8dac-45fc-a851-d25ad7f5e69a",
   "metadata": {},
   "source": [
    "# 3) Vergleich mit statmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d37f2b-e538-4308-997f-367b0cf56b76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3.1) statmodels Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957c7a3-d821-49b4-a069-3085022eeffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data(10000, 7, [-8, -1.6, 4.1, -10, -9.2, 1.3, 1.6, 2.3])\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d357f4-5a5c-4c3d-a6a6-5309c364337d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3.2) Ausgabe der implementierten Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7eaff-e57e-42a5-bffb-24b67e62f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual, _ = linear_regression_manual_qr(X,y)\n",
    "\n",
    "print(\"\\nErgebnisse der manuellen Berechnung:\\n\")\n",
    "\n",
    "for key, value in manual[0].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"-\" * 50)  # 50 Zeichen lange Linie\n",
    "\n",
    "for key, value in manual[1].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"-\" * 50)  # 50 Zeichen lange Linie\n",
    "\n",
    "df = pd.DataFrame(manual[2])\n",
    "print(df)\n",
    "\n",
    "print(\"-\" * 50)  # 50 Zeichen lange Linie\n",
    "\n",
    "for key, value in manual[3].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10c315-79d4-4ead-a165-3b30af59089a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f86e1f-6d1b-46ab-905e-462090b9bd19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
