{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import t, f\n",
    "import time\n",
    "import matplotlib.pyplot as plt  # Diesen Import hinzufügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Funktionen für Lineare Regression mit QR Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Lösen eines LGS durch Rückwärts Einsetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_substitution(A, y):\n",
    "    n = A.shape[0]  # Dimension der Dreiecksmatrix bestimmen\n",
    "    b = np.zeros(n)  # Lösung für den Vektor b\n",
    "\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        if A[i, i] == 0:\n",
    "            raise ValueError(\"Die Matrix A enthält eine Null auf der Diagonale, keine eindeutige Lösung möglich.\")\n",
    "        \n",
    "        b[i] = (y[i] - np.dot(A[i, i+1:], b[i+1:])) / A[i, i]\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) QR Zerlegung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt(X):\n",
    "    n, m = X.shape\n",
    "    Q = np.zeros((n, m))\n",
    "    R = np.zeros((m, m))\n",
    "\n",
    "    for j in range(m):\n",
    "        v = X[:, j]\n",
    "        \n",
    "        for i in range(j):\n",
    "            R[i, j] = np.dot(Q[:, i], X[:, j])\n",
    "            v = v - R[i, j] * Q[:, i]\n",
    "\n",
    "        R[j, j] = np.linalg.norm(v)\n",
    "        Q[:, j] = v / R[j, j]\n",
    "\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Datensatz simulieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(n, p, beta_true):\n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(n, p)\n",
    "    X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "    y = X @ beta_true + np.random.randn(n) * 0.1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Funktion zur Durchführung der linearen Regression \n",
    "\n",
    "- simuliert einen Datensatz\n",
    "- führt die lineare Regression durch\n",
    "- berechnet alle Metriken, die auch statmodels `summary()` ausgibt\n",
    "- misst die Zeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_manual_qr(X, y):\n",
    "    start_time = time.time()\n",
    "    Q, R = gram_schmidt(X)\n",
    "    beta = backward_substitution(R, Q.T @ y)\n",
    "\n",
    "    #sonstige Metriken berechnen\n",
    "    n, k = X.shape\n",
    "    k-= 1 # -1, weil die Matrix X eine einser-Spalte für den Offset beinhaltet, der ignoriert werden muss\n",
    "    df_residuals = n - k - 1 #Freiheitsgrade\n",
    "\n",
    "    XtX = np.dot(X.T, X)\n",
    "    XtX_inv = np.linalg.inv(XtX)\n",
    "\n",
    "    y_pred = np.dot(X, beta) # mit den durch QR berechneten Betas die vorhergesagten y-Werte des linReg Modells bestimmen\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    r_quadrat = 1 - (np.sum((residuals) ** 2) / np.sum((y - np.mean(y)) ** 2))\n",
    "    adjusted_r_quadrat = 1 - ((n - 1) / df_residuals) * (np.sum((residuals) ** 2) / np.sum((y - np.mean(y)) ** 2))\n",
    "   \n",
    "    SSE = np.sum(residuals ** 2)\n",
    "    SSR = np.sum((y_pred - np.mean(y)) ** 2)\n",
    "    sigma_hat = np.sqrt(SSE / df_residuals)\n",
    "\n",
    "    f_statistics = (SSR / k) / (SSE / df_residuals)\n",
    "    f_p_wert = f.sf(f_statistics, k, df_residuals)\n",
    "    log_likelihood = -n / 2 * (np.log(2 * np.pi) + np.log(sigma_hat ** 2) + SSE / (n * sigma_hat ** 2))\n",
    "\n",
    "    AIC = 2 * k - 2 * log_likelihood\n",
    "    BIC = np.log(n) * k - 2 * log_likelihood\n",
    "\n",
    "    cov_matrix = (sigma_hat ** 2) * XtX_inv\n",
    "\n",
    "    se = np.sqrt(np.diag(cov_matrix))\n",
    "    t_werte = beta / se\n",
    "    p_werte = 2 * (1 - t.cdf(np.abs(t_werte), df_residuals))\n",
    "\n",
    "    # Konfidenzintervall für die beta-Werte\n",
    "    alpha = 0.05\n",
    "    t_crit = stats.t.ppf(1 - alpha / 2, df=df_residuals)  # kritischer t-Wert\n",
    "    conf_int_lower = beta - t_crit * se\n",
    "    conf_int_upper = beta + t_crit * se\n",
    "\n",
    "    # Omnibus-Test\n",
    "    skewness = stats.skew(residuals)\n",
    "    kurtosis = stats.kurtosis(residuals, fisher=False)\n",
    "    omnibus_stat = (n / 6) * (skewness**2 + ((kurtosis - 3)**2) / 4)\n",
    "    prob_omnibus = 1 - stats.chi2.cdf(omnibus_stat, df=2)\n",
    "\n",
    "    # Durbin-Watson-Statistik\n",
    "    dw_statistic = np.sum(np.diff(residuals) ** 2) / np.sum(residuals ** 2)\n",
    "\n",
    "    # Jarque-Bera-Test\n",
    "    jarque_bera_stat = (n / 6) * (skewness**2 + (kurtosis - 3)**2 / 4)\n",
    "    prob_jb = 1 - stats.chi2.cdf(jarque_bera_stat, df=2)\n",
    "\n",
    "    # Konditionsnummer\n",
    "    # U, s, Vt = np.linalg.svd(X)\n",
    "    # cond_number = np.max(s) / np.min(s)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    result = [\n",
    "        {'Dep. Variable': 'y',\n",
    "         'Method': 'Linear Regression with QR Decomposition',\n",
    "         'Observations': n,\n",
    "         'df': df_residuals,\n",
    "         'Variables': k},\n",
    "        {'R-Squared': r_quadrat,\n",
    "         'Adj. R-Squared': adjusted_r_quadrat,\n",
    "         'F-statistic': f_statistics,\n",
    "         'Prob (F-statistic)': f_p_wert,\n",
    "         'Log-Likelihood': log_likelihood,\n",
    "         'AIC': AIC,\n",
    "         'BIC': BIC},\n",
    "        {'coef': beta,\n",
    "         'std err': se,\n",
    "         't': t_werte,\n",
    "         'P>abs(t)': p_werte,\n",
    "         'lower boundary': conf_int_lower,\n",
    "         'upper boundary': conf_int_upper},\n",
    "        {'Ombibus': omnibus_stat,\n",
    "         'Prob(Omnibus)': prob_omnibus,\n",
    "         'Skew': skewness,\n",
    "         'Kurtosis': kurtosis,\n",
    "         'Durbin-Watson': dw_statistic,\n",
    "         'Jarque-Bera (JB)': jarque_bera_stat,\n",
    "         'Prob(JB)': prob_jb}\n",
    "         #'Cond. No.': cond_number}\n",
    "          \n",
    "    ]\n",
    "\n",
    "    return result, elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5) Funktion für Durchführung des Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(n_list, beta_true, p, repetitions=5):\n",
    "    results = []\n",
    "\n",
    "    for n in n_list:\n",
    "        times = []\n",
    "        for _ in range(repetitions):\n",
    "            X, y = create_data(n, p, beta_true)\n",
    "            beta, elapsed_time = linear_regression_manual_qr(X, y)\n",
    "            times.append(elapsed_time)\n",
    "\n",
    "        avg_time = np.mean(times)\n",
    "        std_time = np.std(times)\n",
    "        results.append([n, avg_time, std_time])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Durchführung des Benchmarks und Ausgeben der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Durchführung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [100, 500, 1000, 5000, 10000, 50000, 100000, 200000, 500000, 1000000]\n",
    "beta_true = [-8, -1.6, 4.1, -10, -9.2, 1.3, 1.6, 2.3]\n",
    "p = 7\n",
    "benchmark_results = run_benchmark(n_values, beta_true, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Ausgeben der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in benchmark_results:\n",
    "    print(\"\\n Datenzeilen: \", i[0])\n",
    "    print(\"Laufzeit: \", i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Plotten der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_times = [result[1] for result in benchmark_results]\n",
    "std_times = [result[2] for result in benchmark_results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(n_values, avg_times, yerr=std_times, fmt='-o', ecolor='r', capsize=5, label='Durchschnittliche Rechenzeit mit Standardabweichung')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Anzahl der Beobachtungen (n)')\n",
    "plt.ylabel('Rechenzeit (s)')\n",
    "plt.title('Rechenzeit der QR-Dekompositions-basierten Regression für wachsendes n')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Vergleich mit statmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) statmodels Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 2.463e+06\n",
      "Date:                Sun, 13 Oct 2024   Prob (F-statistic):               0.00\n",
      "Time:                        13:51:12   Log-Likelihood:                 8740.0\n",
      "No. Observations:               10000   AIC:                        -1.746e+04\n",
      "Df Residuals:                    9992   BIC:                        -1.741e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -7.9986      0.005  -1686.761      0.000      -8.008      -7.989\n",
      "x1            -1.6001      0.004   -455.423      0.000      -1.607      -1.593\n",
      "x2             4.0995      0.004   1168.820      0.000       4.093       4.106\n",
      "x3           -10.0001      0.004  -2851.307      0.000     -10.007      -9.993\n",
      "x4            -9.1953      0.004  -2619.899      0.000      -9.202      -9.188\n",
      "x5             1.2993      0.003    372.782      0.000       1.292       1.306\n",
      "x6             1.6008      0.003    457.490      0.000       1.594       1.608\n",
      "x7             2.2949      0.004    653.421      0.000       2.288       2.302\n",
      "==============================================================================\n",
      "Omnibus:                        0.742   Durbin-Watson:                   2.004\n",
      "Prob(Omnibus):                  0.690   Jarque-Bera (JB):                0.771\n",
      "Skew:                           0.004   Prob(JB):                        0.680\n",
      "Kurtosis:                       2.958   Cond. No.                         9.72\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X, y = create_data(10000, 7, [-8, -1.6, 4.1, -10, -9.2, 1.3, 1.6, 2.3])\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Ausgabe der implementierten Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ergebnisse der manuellen Berechnung:\n",
      "\n",
      "Dep. Variable: y\n",
      "Method: Linear Regression with QR Decomposition\n",
      "Observations: 10000\n",
      "df: 9992\n",
      "Variables: 7\n",
      "--------------------------------------------------\n",
      "R-Squared: 0.9994208394069305\n",
      "Adj. R-Squared: 0.9994204336699257\n",
      "F-statistic: 2463223.2892255373\n",
      "Prob (F-statistic): 0.0\n",
      "Log-Likelihood: 8740.022091638617\n",
      "AIC: -17466.044183277234\n",
      "BIC: -17415.571800673402\n",
      "--------------------------------------------------\n",
      "        coef   std err            t  P>abs(t)  lower boundary  upper boundary\n",
      "0  -7.998577  0.004742 -1686.760506       0.0       -8.007873       -7.989282\n",
      "1  -1.600072  0.003513  -455.423205       0.0       -1.606959       -1.593185\n",
      "2   4.099500  0.003507  1168.820048       0.0        4.092625        4.106375\n",
      "3 -10.000056  0.003507 -2851.307248       0.0      -10.006930       -9.993181\n",
      "4  -9.195339  0.003510 -2619.899498       0.0       -9.202219       -9.188459\n",
      "5   1.299325  0.003485   372.781716       0.0        1.292492        1.306157\n",
      "6   1.600779  0.003499   457.490219       0.0        1.593920        1.607637\n",
      "7   2.294890  0.003512   653.421187       0.0        2.288006        2.301774\n",
      "--------------------------------------------------\n",
      "Ombibus: 0.771496247566932\n",
      "Prob(Omnibus): 0.6799417652731257\n",
      "Skew: 0.00393795577678016\n",
      "Kurtosis: 2.9576967966773067\n",
      "Durbin-Watson: 2.003826646463087\n",
      "Jarque-Bera (JB): 0.771496247566932\n",
      "Prob(JB): 0.6799417652731257\n"
     ]
    }
   ],
   "source": [
    "manual, _ = linear_regression_manual_qr(X,y)\n",
    "\n",
    "print(\"\\nErgebnisse der manuellen Berechnung:\\n\")\n",
    "\n",
    "for key, value in manual[0].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"-\" * 50)  # 50 Zeichen lange Linie\n",
    "\n",
    "for key, value in manual[1].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"-\" * 50)  # 50 Zeichen lange Linie\n",
    "\n",
    "df = pd.DataFrame(manual[2])\n",
    "print(df)\n",
    "\n",
    "print(\"-\" * 50)  # 50 Zeichen lange Linie\n",
    "\n",
    "for key, value in manual[3].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
