{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe69520-de18-4f7e-a57d-3ce1bf9c801d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bf477c-4d95-43c1-98b3-b204326365e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780a1904-2987-455f-90ef-5de906bf8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.types import DoubleType\n",
    "import time\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efbb38-8ac2-4704-a8d2-c5bf884b37b4",
   "metadata": {},
   "source": [
    "# Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0d7bb0-bb83-4dd1-bc10-c99a76b7af12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/26 17:25:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"spark://spark-master:7077\").appName(\"ManualQRDecomposition\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc8cf8-3584-4cdf-88fa-7a3dbd17c89a",
   "metadata": {},
   "source": [
    "# 1) Funktionen für Lineare Regression mit QR Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd80614-6695-401e-a843-8b9e585e4f28",
   "metadata": {},
   "source": [
    "## 1.1) Lösen eines LGS durch Rückwärts Einsetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52d27f0-21af-4b08-ad87-c39f37e81e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_substitution(R, b):\n",
    "    \"\"\"\n",
    "    Solves the upper triangular system Ax = y for x using backward substitution.\n",
    "    \n",
    "    Args:\n",
    "    R: Upper triangular matrix\n",
    "    y (array): The right-hand side vector.\n",
    "    \n",
    "    Returns:\n",
    "    array: Solution vector b.\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    x = np.zeros(n)\n",
    "    \n",
    "    for i in range(n-1, -1, -1):\n",
    "        sum_val = 0\n",
    "        for j in range(i+1, n):\n",
    "            sum_val += R[i, j] * x[j]\n",
    "        \n",
    "        if abs(R[i, i]) > 1e-10:  # Check for numerical stability\n",
    "            x[i] = (b[i] - sum_val) / R[i, i]\n",
    "        else:\n",
    "            x[i] = 0\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699aa431-e57f-42a3-b539-20c118e38599",
   "metadata": {},
   "source": [
    "## 1.2) QR Zerlegung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60304a-4ec6-4928-989b-1d4a5c8cb70c",
   "metadata": {},
   "source": [
    "### 1.2.1) Gram Schmidt ohne Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc07ed62-e4b1-42aa-99fd-0f649fc8b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_qr_decomposition(X_array):\n",
    "    \"\"\"\n",
    "    Manual implementation of QR decomposition using Gram-Schmidt process.\n",
    "    \n",
    "    Args:\n",
    "        X_array: Input matrix as numpy array\n",
    "        \n",
    "    Returns:\n",
    "        Q: Orthogonal matrix\n",
    "        R: Upper triangular matrix\n",
    "    \"\"\"\n",
    "    n, m = X_array.shape\n",
    "    Q = np.zeros((n, m))\n",
    "    R = np.zeros((m, m))\n",
    "    \n",
    "    for j in range(m):\n",
    "        v = X_array[:, j].copy()\n",
    "        \n",
    "        for i in range(j):\n",
    "            R[i, j] = 0\n",
    "            for k in range(n):\n",
    "                R[i, j] += Q[k, i] * X_array[k, j]\n",
    "            \n",
    "            for k in range(n):\n",
    "                v[k] = v[k] - R[i, j] * Q[k, i]\n",
    "        \n",
    "        norm = 0\n",
    "        for k in range(n):\n",
    "            norm += v[k] * v[k]\n",
    "        norm = np.sqrt(norm)\n",
    "        \n",
    "        R[j, j] = norm\n",
    "        \n",
    "        if norm > 1e-10:  # Avoid division by very small numbers\n",
    "            for k in range(n):\n",
    "                Q[k, j] = v[k] / norm\n",
    "        else:\n",
    "            for k in range(n):\n",
    "                Q[k, j] = 0\n",
    "    \n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515461cc-cc5e-4bec-b04a-7d90294d8f71",
   "metadata": {},
   "source": [
    "### 1.2.1) Gram Schmidt mit Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8830863b-6f7b-4317-b0e6-bc25d95d1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt(X_df):\n",
    "    X_rdd = X_df.rdd.cache()\n",
    "    m = len(X_df.first().features)\n",
    "    Q = []\n",
    "    R = np.zeros((m, m))\n",
    "\n",
    "    for j in range(m):\n",
    "        v = X_rdd.map(lambda row: row.features[j]).collect()\n",
    "        \n",
    "        for i in range(j):\n",
    "            R[i, j] = np.dot(Q[i], v)\n",
    "            v -= R[i, j] * Q[i]\n",
    "\n",
    "        R[j, j] = np.linalg.norm(v)\n",
    "        Q.append(v / R[j, j])\n",
    "    \n",
    "    R_dict = {i: R[i, :] for i in range(m)}\n",
    "\n",
    "    Q_df = spark.createDataFrame([Row(features=DenseVector(q)) for q in zip(*Q)])\n",
    "\n",
    "    return Q_df, R_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b829778-5e93-476e-8c5e-2b93dee3beab",
   "metadata": {},
   "source": [
    "## 1.3) Datensatz simulieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8df7af-e5c3-4194-b54b-64bdaa2b25ff",
   "metadata": {},
   "source": [
    "### 1.3.1) Datensatz simulieren ohne Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98535df-d721-4911-bb4b-1dab272760d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_numpy(n, p, beta_true):\n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(n, p)\n",
    "    X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "    y = X @ beta_true + np.random.randn(n) * 0.1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3053fff-9fd2-4383-b210-efd0a70ca89e",
   "metadata": {},
   "source": [
    "### 1.3.2) Datensatz simulieren mit Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0d5d5e-a431-4674-8e25-fadb4a65e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_spark(n_samples, n_features, beta_true, noise_std=0.1, partition_size=10000):\n",
    "    \"\"\"\n",
    "    Generates synthetic data optimized for distributed processing.\n",
    "    \n",
    "    Args:\n",
    "        spark: SparkSession\n",
    "        n: Number of observations\n",
    "        p: Number of features\n",
    "        beta_true: True coefficients\n",
    "        num_partitions: Number of partitions for distributed data\n",
    "    \"\"\"\n",
    "    def generate_partition(partition_size):\n",
    "        X = np.random.randn(partition_size, n_features)\n",
    "        X = np.column_stack([np.ones(partition_size), X])\n",
    "        y = X @ beta_true + np.random.normal(0, noise_std, partition_size)\n",
    "        return [(Vectors.dense(x), float(y_i)) for x, y_i in zip(X, y)]\n",
    "    \n",
    "    num_partitions = max(n_samples // partition_size, spark.sparkContext.defaultParallelism)\n",
    "    samples_per_partition = n_samples // num_partitions\n",
    "    \n",
    "    rdd = (spark.sparkContext\n",
    "           .parallelize(range(num_partitions), num_partitions)\n",
    "           .flatMap(lambda _: generate_partition(samples_per_partition)))\n",
    "    \n",
    "    return spark.createDataFrame(rdd, [\"features\", \"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d14c3-ea1f-4d92-8823-f39e6ecc1023",
   "metadata": {},
   "source": [
    "## 1.4) Funktion zur Durchführung der linearen Regression \n",
    "\n",
    "- simuliert einen Datensatz\n",
    "- führt die lineare Regression durch\n",
    "- berechnet alle Metriken, die auch statmodels `summary()` ausgibt\n",
    "- misst die Zeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ea64d-6edc-4b37-9ff9-ede937bf1939",
   "metadata": {},
   "source": [
    "### 1.4.1 Lineare Regression mit Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15e67860-c100-450b-a82a-8147fc35694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_manual_qr(X, y):\n",
    "    start_time = time.time()\n",
    "    Q, R = manual_qr_decomposition(X)\n",
    "\n",
    "    # Calculate Qt * y without collecting Q into memory\n",
    "    Qt_y = np.array(Q.rdd.map(lambda row: sum(row.features[i] * y[i] for i in range(len(row.features)))).collect())\n",
    "    beta = backward_substitution(R, Qt_y)\n",
    "\n",
    "    # Calculate residuals and other statistics without collecting X or y\n",
    "    residuals = y - X.rdd.map(lambda row: np.dot(row.features, beta)).collect()\n",
    "    n = X.count()\n",
    "    k = len(beta)  # Assuming that beta includes the intercept\n",
    "    df_residuals = n - k\n",
    "\n",
    "    # Compute sum of squared errors (SSE) and total sum of squares (SST) locally\n",
    "    SSE = np.sum(np.square(residuals))\n",
    "    mean_y = y.mean()  # Assuming y is already a local object\n",
    "    SST = np.sum(np.square(y - mean_y))\n",
    "\n",
    "    # R-squared and Adjusted R-squared calculations\n",
    "    r_squared = 1 - (SSE / SST)\n",
    "    adjusted_r_squared = 1 - ((1 - r_squared) * (n - 1) / df_residuals)\n",
    "\n",
    "    # F-statistic calculation\n",
    "    MSR = (SST - SSE) / (k - 1)\n",
    "    f_statistic = MSR / (SSE / df_residuals)\n",
    "    p_value_f = 1 - stats.f.cdf(f_statistic, k - 1, df_residuals)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    results = {\n",
    "        'Observations': n,\n",
    "        'R-squared': r_squared,\n",
    "        'Adjusted R-squared': adjusted_r_squared,\n",
    "        'F-statistic': f_statistic,\n",
    "        'p-value (F-statistic)': p_value_f,\n",
    "        'Residual standard error': np.sqrt(SSE / df_residuals),\n",
    "        'Degrees of freedom': df_residuals\n",
    "    }\n",
    "\n",
    "    return results, elapsed_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f46832-388d-431c-94e7-7158f2545563",
   "metadata": {},
   "source": [
    "### 1.4.2 Optimiert für Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9e0c2d7-c257-47ee-a9f1-8e185dbdac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ols_manual(df):\n",
    "    \"\"\"\n",
    "    Fit OLS using manual QR decomposition and backward substitution, with extended statistics.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Calculate combined QR decomposition across partitions\n",
    "    def process_partition(iterator):\n",
    "        # Local arrays for QR decomposition\n",
    "        X_local = []\n",
    "        y_local = []\n",
    "        for row in iterator:\n",
    "            X_local.append(row.features.toArray())\n",
    "            y_local.append(row.y)\n",
    "        \n",
    "        # Early exit if partition is empty\n",
    "        if not X_local:\n",
    "            return []\n",
    "        \n",
    "        X_local = np.vstack(X_local)\n",
    "        y_local = np.array(y_local)\n",
    "        \n",
    "        # Perform local QR decomposition\n",
    "        Q_local, R_local = manual_qr_decomposition(X_local)\n",
    "        \n",
    "        # Calculate local Q^T y\n",
    "        Qty_local = np.dot(Q_local.T, y_local)\n",
    "        \n",
    "        return [(R_local, Qty_local)]\n",
    "    \n",
    "    # Aggregate QR decomposition results\n",
    "    results = df.rdd.mapPartitions(process_partition).reduce(lambda a, b: (\n",
    "        a[0] + b[0],  # Sum R matrices\n",
    "        a[1] + b[1]   # Sum Q^T y vectors\n",
    "    ))\n",
    "    \n",
    "    R_total, Qty_total = results\n",
    "    \n",
    "    # Step 2: Solve for beta using the aggregated QR components\n",
    "    beta = backward_substitution(R_total, Qty_total)\n",
    "    \n",
    "    # Step 3: Calculate residuals and additional statistics in a second RDD pass\n",
    "    def compute_stats(iterator):\n",
    "        # Local arrays for computing residuals\n",
    "        X_local = []\n",
    "        y_local = []\n",
    "        for row in iterator:\n",
    "            X_local.append(row.features.toArray())\n",
    "            y_local.append(row.y)\n",
    "        \n",
    "        if not X_local:\n",
    "            return []\n",
    "        \n",
    "        X_local = np.vstack(X_local)\n",
    "        y_local = np.array(y_local)\n",
    "        y_pred = np.dot(X_local, beta)\n",
    "        residuals = y_local - y_pred\n",
    "        \n",
    "        # Compute statistics locally\n",
    "        ss_res = np.sum(residuals ** 2)\n",
    "        ss_tot = np.sum((y_local - np.mean(y_local)) ** 2)\n",
    "        \n",
    "        return [(ss_res, ss_tot, residuals)]\n",
    "    \n",
    "    # Aggregate residual statistics\n",
    "    stats_results = df.rdd.mapPartitions(compute_stats).reduce(lambda a, b: (\n",
    "        a[0] + b[0],  # Sum of squared residuals\n",
    "        a[1] + b[1],  # Total sum of squares\n",
    "        np.concatenate([a[2], b[2]])  # All residuals for skew and kurtosis\n",
    "    ))\n",
    "    \n",
    "    ss_res, ss_tot, all_residuals = stats_results\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    n_samples = df.count()\n",
    "    p = len(beta)\n",
    "    \n",
    "    # Calculate advanced statistics\n",
    "    mse = ss_res / (n_samples - p)\n",
    "    f_stat = ((ss_tot - ss_res) / p) / (ss_res / (n_samples - p - 1))\n",
    "    skewness = stats.skew(all_residuals)\n",
    "    kurtosis = stats.kurtosis(all_residuals, fisher=False)\n",
    "    \n",
    "    # More computations (AIC, BIC, etc.) can be added here using `n_samples`, `p`, `mse`, etc.\n",
    "    \n",
    "    computation_time = time.time() - start_time\n",
    "    \n",
    "    summary = {\n",
    "        'r_squared': r_squared,\n",
    "        'adj_r_squared': 1 - (1 - r_squared) * (n_samples - 1) / (n_samples - p - 1),\n",
    "        'mse': mse,\n",
    "        'f_statistic': f_stat,\n",
    "        'skewness': skewness,\n",
    "        'kurtosis': kurtosis,\n",
    "        'computation_time': computation_time,\n",
    "        'n_samples': n_samples,\n",
    "        'n_features': p\n",
    "    }\n",
    "    \n",
    "    return beta, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4560b59-a830-4be4-a0ab-814ae0cdd1ba",
   "metadata": {},
   "source": [
    "## 1.5) Funktion für Durchführung des Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a3f13-0fb2-494f-98d2-137e5fa557bc",
   "metadata": {},
   "source": [
    "# Berechnung für Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f44301-7434-41a8-bebe-410ba1b9ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark_numpy(n_list, beta_true, p, repetitions=10):\n",
    "    results = []\n",
    "\n",
    "    for n in n_list:\n",
    "        times = []\n",
    "        for _ in range(repetitions):\n",
    "            X, y = create_data_numpy(n, p, beta_true)\n",
    "            beta, elapsed_time = linear_regression_manual_qr(X, y)\n",
    "            times.append(elapsed_time)\n",
    "\n",
    "        avg_time = np.mean(times)\n",
    "        std_time = np.std(times)\n",
    "        results.append([n, avg_time, std_time])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c2e2ba-9e63-4d63-8115-0fe80afacb22",
   "metadata": {},
   "source": [
    "### Berechnung für eine Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31b19a49-c538-4f47-ac43-4234871356e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_benchmark_range(max_n, p, beta_true, step_size=100000, repetitions=10):\n",
    "    \"\"\"Run benchmarking with fixed step size increments.\"\"\"\n",
    "    #n_values = np.arange(step_size, max_n + step_size, step_size, dtype=int)\n",
    "    n_values = np.logspace(5, np.log10(max_n), 10, dtype=int)\n",
    "    results = []\n",
    "    \n",
    "    for n in n_values:\n",
    "        times = []\n",
    "        r_squares = []\n",
    "        successful_runs = 0\n",
    "        \n",
    "        print(f\"\\nBenchmarking n={n:,} samples...\")\n",
    "        \n",
    "        for i in range(repetitions):\n",
    "            try:\n",
    "                df = create_data_spark(n, p, beta_true)\n",
    "                start_time = time.time()\n",
    "                beta, summary = fit_ols_manual(df)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                \n",
    "                times.append(elapsed_time)\n",
    "                r_squares.append(summary['r_squared'])\n",
    "                successful_runs += 1\n",
    "                \n",
    "                print(f\"  Run {i+1}: time={elapsed_time:.2f}s, R²={summary['r_squared']:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Run {i+1} failed: {str(e)}\")\n",
    "        \n",
    "        if successful_runs > 0:\n",
    "            result = {\n",
    "                'n_samples': n,\n",
    "                'n_features': p,\n",
    "                'mean_time': np.mean(times),\n",
    "                'std_time': np.std(times),\n",
    "                'mean_r_squared': np.mean(r_squares),\n",
    "                'std_r_squared': np.std(r_squares),\n",
    "                'successful_runs': successful_runs\n",
    "            }\n",
    "            results.append(result)\n",
    "            6\n",
    "            print(f\"\\nSummary for n={n:,}:\")\n",
    "            print(f\"  Mean time: {result['mean_time']:.2f}s ± {result['std_time']:.2f}s\")\n",
    "            print(f\"  Mean R²: {result['mean_r_squared']:.4f} ± {result['std_r_squared']:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee49a82-d6f0-4301-a20e-3f03407be25a",
   "metadata": {},
   "source": [
    "### Berechnung für einen festen Wert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4726dfbf-79ed-4be7-87ca-222d8aaa810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_benchmark_point(n, p, beta_true, repetitions=1):\n",
    "    \"\"\"Run benchmarking for a single sample size n.\"\"\"\n",
    "    results = []\n",
    "    times = []\n",
    "    r_squares = []\n",
    "    successful_runs = 0\n",
    "    \n",
    "    print(f\"\\nBenchmarking n={n:,} samples...\")\n",
    "    \n",
    "    for i in range(repetitions):\n",
    "        try:\n",
    "            df = create_data_spark(n, p, beta_true)\n",
    "            start_time = time.time()\n",
    "            beta, summary = fit_ols_manual(df)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            times.append(elapsed_time)\n",
    "            r_squares.append(summary['r_squared'])\n",
    "            successful_runs += 1\n",
    "            \n",
    "            print(f\"  Run {i+1}: time={elapsed_time:.2f}s, R²={summary['r_squared']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Run {i+1} failed: {str(e)}\")\n",
    "    \n",
    "    if successful_runs > 0:\n",
    "        result = {\n",
    "            'n_samples': n,\n",
    "            'n_features': p,\n",
    "            'mean_time': np.mean(times),\n",
    "            'std_time': np.std(times),\n",
    "            'mean_r_squared': np.mean(r_squares),\n",
    "            'std_r_squared': np.std(r_squares),\n",
    "            'successful_runs': successful_runs\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"\\nSummary for n={n:,}:\")\n",
    "        print(f\"  Mean time: {result['mean_time']:.2f}s ± {result['std_time']:.2f}s\")\n",
    "        print(f\"  Mean R²: {result['mean_r_squared']:.4f} ± {result['std_r_squared']:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f3e295-03cd-479b-aefc-eb1e577872f8",
   "metadata": {},
   "source": [
    "# 2) Durchführung des Benchmarks und Ausgeben der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09235d19-d83b-489f-8b37-c6069fa456bc",
   "metadata": {},
   "source": [
    "## 2.1) Durchführung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca3874e2-0a3d-4276-a57c-db966351ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_values = [200000, 500000, 1000000, 5000000, 10000000]\n",
    "#n_features = 7\n",
    "#beta_true = np.random.randn(n_features + 1)\n",
    "#benchmark_results = run_benchmark_numpy(n_list=n_values, beta_true=beta_true, p=n_features) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26997485-2f3b-4dd1-95cc-5efb1c860c6a",
   "metadata": {},
   "source": [
    "### Benchmark Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de869ab9-65a4-4416-950d-aa99543a5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 7\n",
    "beta_true = np.random.randn(n_features + 1)  # +1 for intercept\n",
    "results_point = run_benchmark_point(n=10000000, p=n_features, beta_true=beta_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2758cc14-daf0-4cb1-ba29-dce8c9be3059",
   "metadata": {},
   "source": [
    "### Benchmark Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57930b16-9358-40f4-9b00-6afc3fadd71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 7\n",
    "beta_true = np.random.randn(n_features + 1)  # +1 for intercept\n",
    "results_range = run_benchmark_range(max_n=10000000, p=n_features, beta_true=beta_true, step_size=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ba8cd-e4cd-43f1-ae36-a039696ce95a",
   "metadata": {},
   "source": [
    "## 2.2) Ausgeben der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e1f5e-2563-48cc-afc7-fe9b05c7c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in benchmark_results:\n",
    "    print(\"\\n Datenzeilen: \", i[0])\n",
    "    print(\"Laufzeit: \", i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c08178-a41a-40f8-8412-3ae2566974ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_values = [2000000]\n",
    "benchmark_results = run_benchmark(n_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b5098-64e9-4e05-956a-0605c8884113",
   "metadata": {},
   "source": [
    "## 2.3) Plotten der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9c3fa-3f29-4d98-b398-e1fdde5522b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_times = [result[1] for result in benchmark_results]\n",
    "std_times = [result[2] for result in benchmark_results]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(n_values, avg_times, yerr=std_times, fmt='-o', ecolor='r', capsize=5, label='Durchschnittliche Rechenzeit mit Standardabweichung')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Anzahl der Beobachtungen (n)')\n",
    "plt.ylabel('Rechenzeit (s)')\n",
    "plt.title('Rechenzeit der QR-Dekompositions-basierten Regression für wachsendes n')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583fec38-d021-4dce-a50f-e7ec7829cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "\n",
    "def format_benchmark_summary(results: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Format benchmark results into a readable text summary.\n",
    "    \n",
    "    Args:\n",
    "        results: DataFrame containing benchmark results\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string containing the summary\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "    summary.append(\"==============================================================================\")\n",
    "    summary.append(\"                              Benchmark Results                                \")\n",
    "    summary.append(\"==============================================================================\")\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_samples = len(results)\n",
    "    avg_r_squared = results['mean_r_squared'].mean()\n",
    "    total_successful = results['successful_runs'].sum()\n",
    "    \n",
    "    summary.append(f\"Total test points:               {total_samples}\")\n",
    "    summary.append(f\"Average R-squared:               {avg_r_squared:.4f}\")\n",
    "    summary.append(f\"Total successful runs:           {total_successful}\")\n",
    "    summary.append(\"------------------------------------------------------------------------------\")\n",
    "    summary.append(\"   Samples    Features     Time (s)    Std Time    R-squared    Std R²\")\n",
    "    summary.append(\"------------------------------------------------------------------------------\")\n",
    "    \n",
    "    for _, row in results.iterrows():\n",
    "        summary.append(\n",
    "            f\"{row['n_samples']:>10,d} \"\n",
    "            f\"{row['n_features']:>10d} \"\n",
    "            f\"{row['mean_time']:>11.4f} \"\n",
    "            f\"{row['std_time']:>11.4f} \"\n",
    "            f\"{row['mean_r_squared']:>11.4f} \"\n",
    "            f\"{row['std_r_squared']:>10.4f}\"\n",
    "        )\n",
    "    \n",
    "    summary.append(\"==============================================================================\")\n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "def plot_benchmark_results(results: pd.DataFrame, plot_type: str = 'all'):\n",
    "    \"\"\"\n",
    "    Plot benchmark results with various visualizations.\n",
    "    \n",
    "    Args:\n",
    "        results: DataFrame containing benchmark results\n",
    "        plot_type: Type of plot to generate ('time', 'r_squared', or 'all')\n",
    "    \"\"\"\n",
    "    if plot_type in ['time', 'all']:\n",
    "        # Computation time plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.errorbar(\n",
    "            results['n_samples'], \n",
    "            results['mean_time'],\n",
    "            yerr=results['std_time'],\n",
    "            fmt='o-',\n",
    "            capsize=5,\n",
    "            label='Computation Time'\n",
    "        )\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Sample Size (n)')\n",
    "        plt.ylabel('Computation Time (s)')\n",
    "        plt.title('Benchmarking Computation Time by Sample Size')\n",
    "        plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if plot_type in ['r_squared', 'all']:\n",
    "        # R-squared plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.errorbar(\n",
    "            results['n_samples'],\n",
    "            results['mean_r_squared'],\n",
    "            yerr=results['std_r_squared'],\n",
    "            fmt='o-',\n",
    "            capsize=5,\n",
    "            color='green',\n",
    "            label='R-squared'\n",
    "        )\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Sample Size (n)')\n",
    "        plt.ylabel('R-squared')\n",
    "        plt.title('Model R-squared by Sample Size')\n",
    "        plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_benchmark_comparison(results: List[pd.DataFrame], labels: List[str]):\n",
    "    \"\"\"\n",
    "    Plot benchmark results comparing multiple implementations or configurations.\n",
    "    \n",
    "    Args:\n",
    "        results: List of DataFrames containing benchmark results for different implementations\n",
    "        labels: List of labels for each implementation\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for df, label in zip(results, labels):\n",
    "        plt.errorbar(\n",
    "            df['n_samples'],\n",
    "            df['mean_time'],\n",
    "            yerr=df['std_time'],\n",
    "            fmt='o-',\n",
    "            capsize=5,\n",
    "            label=label\n",
    "        )\n",
    "    \n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Sample Size (n)')\n",
    "    plt.ylabel('Computation Time (s)')\n",
    "    plt.title('Benchmark Comparison')\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3039da8e-a2b7-4253-975c-24da44bf21b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking n=100,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 1: time=3.22s, R²=0.9994\n",
      "\n",
      "Summary for n=100,000:\n",
      "  Mean time: 3.22s ± 0.00s\n",
      "  Mean R²: 0.9994 ± 0.0000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'format_benchmark_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m results_df \u001b[38;5;241m=\u001b[39m run_benchmark_point(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m, p\u001b[38;5;241m=\u001b[39mn_features, beta_true\u001b[38;5;241m=\u001b[39mbeta_true)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Print formatted summary\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mformat_benchmark_summary\u001b[49m(results_df))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Plot results\u001b[39;00m\n\u001b[1;32m      7\u001b[0m plot_benchmark_results(results_df, plot_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'format_benchmark_summary' is not defined"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve RDD 1117\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409)\n",
      "\tat java.net.ServerSocket.implAccept(ServerSocket.java:560)\n",
      "\tat java.net.ServerSocket.accept(ServerSocket.java:528)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:65)\n"
     ]
    }
   ],
   "source": [
    "results_df = run_benchmark_point(n=100000, p=n_features, beta_true=beta_true)\n",
    "\n",
    "# Print formatted summary\n",
    "print(format_benchmark_summary(results_df))\n",
    "\n",
    "# Plot results\n",
    "plot_benchmark_results(results_df, plot_type='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30124dce-8dac-45fc-a851-d25ad7f5e69a",
   "metadata": {},
   "source": [
    "# 3) Vergleich mit statmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d37f2b-e538-4308-997f-367b0cf56b76",
   "metadata": {},
   "source": [
    "## 3.1) statmodels Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957c7a3-d821-49b4-a069-3085022eeffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data(10000, 7, [-8, -1.6, 4.1, -10, -9.2, 1.3, 1.6, 2.3])\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d357f4-5a5c-4c3d-a6a6-5309c364337d",
   "metadata": {},
   "source": [
    "## 3.2) Ausgabe der implementierten Methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7eaff-e57e-42a5-bffb-24b67e62f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual, _ = linear_regression_manual_qr(X,y)\n",
    "\n",
    "print(\"\\nErgebnisse der manuellen Berechnung:\\n\")\n",
    "\n",
    "for key, value in manual[0].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"-\" * 50)  # 50 Zeichen lange Linie\n",
    "\n",
    "for key, value in manual[1].items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"-\" * 50)  # 50 Zeichen lange Linie\n",
    "\n",
    "df = pd.DataFrame(manual[2])\n",
    "print(df)\n",
    "\n",
    "print(\"-\" * 50)  # 50 Zeichen lange Linie\n",
    "\n",
    "for key, value in manual[3].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10c315-79d4-4ead-a165-3b30af59089a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f86e1f-6d1b-46ab-905e-462090b9bd19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
