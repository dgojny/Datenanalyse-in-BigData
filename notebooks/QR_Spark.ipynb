{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe69520-de18-4f7e-a57d-3ce1bf9c801d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bf477c-4d95-43c1-98b3-b204326365e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780a1904-2987-455f-90ef-5de906bf8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.types import DoubleType\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scipy_stats\n",
    "from scipy.stats import t, f\n",
    "import time\n",
    "import matplotlib.pyplot as plt  # Diesen Import hinzufügen\n",
    "from numpy.linalg import LinAlgError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efbb38-8ac2-4704-a8d2-c5bf884b37b4",
   "metadata": {},
   "source": [
    "# Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0d7bb0-bb83-4dd1-bc10-c99a76b7af12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/30 17:24:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"spark://spark-master:7077\").appName(\"ManualQRDecomposition\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc8cf8-3584-4cdf-88fa-7a3dbd17c89a",
   "metadata": {},
   "source": [
    "# 1) Funktionen für Lineare Regression mit QR Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd80614-6695-401e-a843-8b9e585e4f28",
   "metadata": {},
   "source": [
    "## 1.1) Lösen eines LGS durch Rückwärts Einsetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52d27f0-21af-4b08-ad87-c39f37e81e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_substitution(R, b):\n",
    "    \"\"\"\n",
    "    Solves the upper triangular system Rx = b for x using backward substitution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    R : ndarray\n",
    "        Upper triangular matrix from QR decomposition\n",
    "    b : ndarray\n",
    "        The right-hand side vector\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        Solution vector x that satisfies Rx = b\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Implements classic backward substitution algorithm\n",
    "    - Includes numerical stability check (threshold of 1e-10)\n",
    "    - Returns zero for numerically unstable solutions\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    x = np.zeros(n)\n",
    "    \n",
    "    for i in range(n-1, -1, -1):\n",
    "        sum_val = 0\n",
    "        for j in range(i+1, n):\n",
    "            sum_val += R[i, j] * x[j]\n",
    "        \n",
    "        if abs(R[i, i]) > 1e-10:  # Check for numerical stability\n",
    "            x[i] = (b[i] - sum_val) / R[i, i]\n",
    "        else:\n",
    "            x[i] = 0\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699aa431-e57f-42a3-b539-20c118e38599",
   "metadata": {},
   "source": [
    "## 1.2) QR Zerlegung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60304a-4ec6-4928-989b-1d4a5c8cb70c",
   "metadata": {},
   "source": [
    "### 1.2.1) Gram Schmidt ohne Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc07ed62-e4b1-42aa-99fd-0f649fc8b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_qr_decomposition(X_array):\n",
    "    \"\"\"\n",
    "    Performs QR decomposition using modified Gram-Schmidt with numerical stability handling.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_array : ndarray\n",
    "        Input matrix to decompose, shape (n, m)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Q : ndarray\n",
    "        Orthogonal matrix, shape (n, m)\n",
    "    R : ndarray\n",
    "        Upper triangular matrix, shape (m, m)\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Implements modified Gram-Schmidt process\n",
    "    - Includes numerical stability threshold (1e-12)\n",
    "    - Returns zeros for numerically unstable columns\n",
    "    \"\"\"\n",
    "    n, m = X_array.shape\n",
    "    Q = np.zeros((n, m))\n",
    "    R = np.zeros((m, m))\n",
    "    \n",
    "    for j in range(m):\n",
    "        v = X_array[:, j]\n",
    "        for i in range(j):\n",
    "            R[i, j] = np.dot(Q[:, i], X_array[:, j])\n",
    "            v = v - R[i, j] * Q[:, i]\n",
    "        norm = np.linalg.norm(v)\n",
    "        if norm > 1e-12:  # Only normalize if norm is significant\n",
    "            Q[:, j] = v / norm\n",
    "            R[j, j] = norm\n",
    "        else:\n",
    "            R[j, j] = 0\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515461cc-cc5e-4bec-b04a-7d90294d8f71",
   "metadata": {},
   "source": [
    "### 1.2.1) Gram Schmidt mit Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8830863b-6f7b-4317-b0e6-bc25d95d1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt(X):\n",
    "    \"\"\"\n",
    "    Performs classical Gram-Schmidt orthogonalization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        Input matrix to orthogonalize, shape (n, m)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Q : ndarray\n",
    "        Orthogonal matrix, shape (n, m)\n",
    "    R : ndarray\n",
    "        Upper triangular matrix, shape (m, m)\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Implements classical Gram-Schmidt orthogonalization\n",
    "    - No explicit numerical stability checks\n",
    "    - May be less stable than modified Gram-Schmidt for ill-conditioned matrices\n",
    "    \"\"\"\n",
    "    n, m = X.shape\n",
    "    Q = np.zeros((n, m))\n",
    "    R = np.zeros((m, m))\n",
    "\n",
    "    for j in range(m):\n",
    "        v = X[:, j]\n",
    "        \n",
    "        for i in range(j):\n",
    "            R[i, j] = np.dot(Q[:, i], X[:, j])\n",
    "            v = v - R[i, j] * Q[:, i]\n",
    "\n",
    "        R[j, j] = np.linalg.norm(v)\n",
    "        Q[:, j] = v / R[j, j]\n",
    "\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b829778-5e93-476e-8c5e-2b93dee3beab",
   "metadata": {},
   "source": [
    "## 1.3) Datensatz simulieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8df7af-e5c3-4194-b54b-64bdaa2b25ff",
   "metadata": {},
   "source": [
    "### 1.3.1) Datensatz simulieren ohne Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98535df-d721-4911-bb4b-1dab272760d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_numpy(n, p, beta_true):\n",
    "    \"\"\"\n",
    "    Generates synthetic regression data using NumPy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of samples\n",
    "    p : int\n",
    "        Number of features (excluding intercept)\n",
    "    beta_true : ndarray\n",
    "        True coefficient values including intercept\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X : ndarray\n",
    "        Design matrix with intercept column, shape (n, p+1)\n",
    "    y : ndarray\n",
    "        Target variable vector, shape (n,)\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Uses fixed random seed (42) for reproducibility\n",
    "    - Adds constant term (intercept) to X\n",
    "    - Adds Gaussian noise with std=0.1 to y\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(n, p)\n",
    "    X = np.column_stack([np.ones(X.shape[0]), X])\n",
    "    y = X @ beta_true + np.random.randn(n) * 0.3\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3053fff-9fd2-4383-b210-efd0a70ca89e",
   "metadata": {},
   "source": [
    "### 1.3.2) Datensatz simulieren mit Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0d5d5e-a431-4674-8e25-fadb4a65e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_spark(n_samples, n_features, beta_true, noise_std=0.3, partition_size=10000):\n",
    "    \"\"\"\n",
    "    Generates distributed synthetic regression data optimized for Spark.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int\n",
    "        Total number of observations\n",
    "    n_features : int\n",
    "        Number of features (excluding intercept)\n",
    "    beta_true : ndarray\n",
    "        True coefficient values including intercept\n",
    "    noise_std : float, optional\n",
    "        Standard deviation of Gaussian noise, default=0.1\n",
    "    partition_size : int, optional\n",
    "        Number of samples per partition, default=10000\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Spark DataFrame with features and target columns\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Generates data in parallel across partitions\n",
    "    - Uses unique random seeds per partition\n",
    "    - Optimized for distributed processing\n",
    "    \"\"\"\n",
    "    def generate_partition(partition_index, partition_size):\n",
    "        np.random.seed(42 + partition_index)  # Unique seed for each partition to avoid duplicate data\n",
    "        X = np.random.randn(partition_size, n_features)\n",
    "        X = np.column_stack([np.ones(partition_size), X])  # Add intercept\n",
    "        y = X @ beta_true + np.random.normal(0, noise_std, partition_size)\n",
    "        return [(Vectors.dense(x), float(y_i)) for x, y_i in zip(X, y)]\n",
    "    \n",
    "    num_partitions = max(n_samples // partition_size, spark.sparkContext.defaultParallelism)\n",
    "    samples_per_partition = n_samples // num_partitions\n",
    "    \n",
    "    # Parallelize the data generation across partitions\n",
    "    rdd = (spark.sparkContext\n",
    "           .parallelize(range(num_partitions), num_partitions)\n",
    "           .flatMap(lambda i: generate_partition(i, samples_per_partition)))\n",
    "    \n",
    "    return spark.createDataFrame(rdd, [\"features\", \"y\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d14c3-ea1f-4d92-8823-f39e6ecc1023",
   "metadata": {},
   "source": [
    "## 1.4) Funktion zur Durchführung der linearen Regression \n",
    "\n",
    "- simuliert einen Datensatz\n",
    "- führt die lineare Regression durch\n",
    "- berechnet alle Metriken, die auch statmodels `summary()` ausgibt\n",
    "- misst die Zeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6acd3-d231-4ac8-bd3f-7c28c9dd525b",
   "metadata": {},
   "source": [
    "### 1.4.1) Funktion zur Berechnung der Statistik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d058ac9-6aeb-4537-a3a9-b916d74b259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics_numpy(X, y, beta, residuals):\n",
    "    \"\"\"\n",
    "    Computes comprehensive regression statistics using NumPy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        Design matrix including intercept\n",
    "    y : ndarray\n",
    "        Target variable vector\n",
    "    beta : ndarray\n",
    "        Estimated coefficients\n",
    "    residuals : ndarray\n",
    "        Model residuals (y - X @ beta)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing various statistics including:\n",
    "        - R-squared and Adjusted R-squared\n",
    "        - F-statistic and p-value\n",
    "        - Standard errors and t-statistics\n",
    "        - AIC and BIC\n",
    "        - Durbin-Watson statistic\n",
    "        - Jarque-Bera test results\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Computes full suite of regression diagnostics\n",
    "    - Includes both model fit and residual diagnostics\n",
    "    \"\"\"\n",
    "    n, k = X.shape\n",
    "    SSE = np.sum(residuals ** 2)\n",
    "    SST = np.sum((y - np.mean(y)) ** 2)\n",
    "    SSR = SST - SSE\n",
    "    df_residuals = n - k\n",
    "    df_model = k - 1\n",
    "    \n",
    "    r_squared = 1 - (SSE / SST)\n",
    "    adj_r_squared = 1 - ((1 - r_squared) * (n - 1) / df_residuals)\n",
    "    \n",
    "    MSE = SSE / df_residuals\n",
    "    MSR = SSR / df_model\n",
    "    f_statistic = MSR / MSE\n",
    "    f_p_value = scipy_stats.f.sf(f_statistic, df_model, df_residuals)\n",
    "    \n",
    "    sigma_squared = MSE\n",
    "    XtX_inv = np.linalg.inv(X.T @ X)\n",
    "    se = np.sqrt(np.diag(sigma_squared * XtX_inv))\n",
    "    t_values = beta / se\n",
    "    p_values = 2 * (1 - scipy_stats.t.cdf(np.abs(t_values), df_residuals))\n",
    "    \n",
    "    skewness = scipy_stats.skew(residuals)\n",
    "    kurtosis = scipy_stats.kurtosis(residuals, fisher=False)\n",
    "    log_likelihood = -0.5 * n * (np.log(2 * np.pi * sigma_squared) + 1)\n",
    "    AIC = 2 * k - 2 * log_likelihood\n",
    "    BIC = n * np.log(SSE / n) + k * np.log(n)\n",
    "    \n",
    "    dw_statistic = np.sum(np.diff(residuals) ** 2) / SSE\n",
    "    \n",
    "    jarque_bera_stat = (n / 6) * (skewness**2 + (kurtosis - 3)**2 / 4)\n",
    "    prob_jb = 1 - scipy_stats.chi2.cdf(jarque_bera_stat, df=2)\n",
    "    \n",
    "    return {\n",
    "        'r_squared': r_squared,\n",
    "        'Adjusted R-squared': adj_r_squared,\n",
    "        'F-statistic': f_statistic,\n",
    "        'Prob (F-statistic)': f_p_value,\n",
    "        'Log-Likelihood': log_likelihood,\n",
    "        'AIC': AIC,\n",
    "        'BIC': BIC,\n",
    "        'coef': beta,\n",
    "        'std err': se,\n",
    "        't': t_values,\n",
    "        'P>|t|': p_values,\n",
    "        'Skew': skewness,\n",
    "        'Kurtosis': kurtosis,\n",
    "        'Durbin-Watson': dw_statistic,\n",
    "        'Jarque-Bera (JB)': jarque_bera_stat,\n",
    "        'Prob(JB)': prob_jb,\n",
    "        'mse': MSE\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc87246e-14b8-4496-9546-33caa28f79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics_partition(iterator, beta):\n",
    "    \"\"\"\n",
    "    Computes partial statistics for a partition of data in Spark.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    iterator : iterator\n",
    "        Iterator over partition rows\n",
    "    beta : ndarray\n",
    "        Estimated coefficients\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (SSE_local, SST_local, SSR_local, y_sum_local, count_local)\n",
    "        Local statistics for the partition\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Designed for distributed computation in Spark\n",
    "    - Handles empty partitions gracefully\n",
    "    - Computes sufficient statistics for later aggregation\n",
    "    \"\"\"\n",
    "    rows = list(iterator)\n",
    "    SSE_local, SST_local, SSR_local = 0, 0, 0\n",
    "    y_sum_local, count_local = 0, 0\n",
    "\n",
    "    if len(rows) == 0:\n",
    "        print(\"Empty partition in compute_statistics_partition.\")\n",
    "        return (0.0, 0.0, 0.0, 0.0, 0)\n",
    "\n",
    "    # First pass to get mean\n",
    "    for row in rows:\n",
    "        y = row.y\n",
    "        y_sum_local += y\n",
    "        count_local += 1\n",
    "\n",
    "    if count_local > 0:\n",
    "        y_mean_local = y_sum_local / count_local\n",
    "\n",
    "        # Second pass for calculations\n",
    "        for row in rows:\n",
    "            X = row.features.toArray()\n",
    "            y = row.y\n",
    "            y_pred = np.dot(X, beta)\n",
    "            residual = y - y_pred\n",
    "            SSE_local += residual ** 2\n",
    "            SST_local += (y - y_mean_local) ** 2\n",
    "\n",
    "        SSR_local = SST_local - SSE_local\n",
    "\n",
    "    return (SSE_local, SST_local, SSR_local, y_sum_local, count_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25d1ea37-2d73-43e1-8360-709c0d154430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_statistics(rdd_stats, n, beta_length, XtX_inv, residuals, beta):\n",
    "    \"\"\"\n",
    "    Aggregates statistics across all partitions in Spark.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd_stats : RDD\n",
    "        RDD containing partial statistics from each partition\n",
    "    n : int\n",
    "        Total number of samples\n",
    "    beta_length : int\n",
    "        Number of coefficients (including intercept)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Aggregated statistics including:\n",
    "        - R-squared and Adjusted R-squared\n",
    "        - F-statistic\n",
    "        - AIC and BIC\n",
    "        - Sample size and feature count\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Implements safe reduction operations\n",
    "    - Handles edge cases and potential errors\n",
    "    - Includes comprehensive error checking\n",
    "    \"\"\"\n",
    "    def safe_reduce(a, b):\n",
    "        try:\n",
    "            return (\n",
    "                a[0] + b[0],\n",
    "                a[1] + b[1],\n",
    "                a[2] + b[2],\n",
    "                a[3] + b[3],\n",
    "                a[4] + b[4]\n",
    "            )\n",
    "        except (IndexError, TypeError) as e:\n",
    "            print(f\"Error in safe_reduce: {str(e)}\")\n",
    "            return a\n",
    "\n",
    "    try:\n",
    "        (SSE, SST, SSR, y_sum_total, total_count) = rdd_stats.reduce(safe_reduce)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in aggregating statistics: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "    # Mean of y over all partitions\n",
    "    y_mean = y_sum_total / total_count if total_count > 0 else 0\n",
    "\n",
    "    # Calculate R-squared and Adjusted R-squared\n",
    "    r_squared = 1 - (SSE / SST) if SST > 0 else 0\n",
    "    adj_r_squared = (\n",
    "        1 - ((1 - r_squared) * (total_count - 1) / (total_count - beta_length))\n",
    "        if total_count > beta_length else 0\n",
    "    )\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE) and F-statistic\n",
    "    MSE = SSE / (total_count - beta_length) if total_count > beta_length else 0\n",
    "    MSR = SSR / (beta_length - 1) if beta_length > 1 else 0\n",
    "    df_model = beta_length - 1\n",
    "    df_residuals = total_count - beta_length\n",
    "    f_statistic = MSR / MSE if MSE > 0 else float('inf')\n",
    "    f_p_value = scipy_stats.f.sf(f_statistic, df_model, df_residuals)\n",
    "    log_likelihood = -0.5 * total_count * (np.log(2 * np.pi * MSE) + 1) if MSE > 0 else float('-inf')\n",
    "\n",
    "    # Calculate AIC and BIC\n",
    "    AIC = total_count * np.log(SSE / total_count) + 2 * beta_length if total_count > 0 else 0\n",
    "    BIC = total_count * np.log(SSE / total_count) + beta_length * np.log(total_count) if total_count > 0 else 0\n",
    "\n",
    "    sigma_squared = MSE\n",
    "    XtX_inv = XtX_inv  # Ensure X and beta are available in scope\n",
    "    std_err = np.sqrt(np.diag(sigma_squared * XtX_inv)) if XtX_inv is not None else [float('nan')] * beta_length\n",
    "    dw_statistic = np.sum(np.diff(residuals) ** 2) / SSE\n",
    "    skewness = scipy_stats.skew(residuals)\n",
    "    kurtosis = scipy_stats.kurtosis(residuals, fisher=False)\n",
    "    jb_statistic = (n / 6) * (skewness**2 + (kurtosis - 3)**2 / 4)\n",
    "    prob_jb = 1 - scipy_stats.chi2.cdf(jb_statistic, df=2)\n",
    "    skew = scipy_stats.skew(residuals)\n",
    "    kurtosis = scipy_stats.kurtosis(residuals, fisher=False)\n",
    "    t_values = beta / std_err\n",
    "    p_values = 2 * (1 - scipy_stats.t.cdf(np.abs(t_values), df_residuals))\n",
    "\n",
    "    # Compile final statistics\n",
    "    stats = {\n",
    "    'r_squared': r_squared,\n",
    "    'Adjusted R-squared': adj_r_squared,\n",
    "    'F-statistic': f_statistic,\n",
    "    'Prob (F-statistic)': f_p_value,\n",
    "    'Log-Likelihood': log_likelihood,\n",
    "    'AIC': AIC,\n",
    "    'BIC': BIC,\n",
    "    'SSE': SSE,\n",
    "    'SSR': SSR,\n",
    "    'SST': SST,\n",
    "    'mse': MSE,\n",
    "    'n_samples': total_count,\n",
    "    'n_features': beta_length,\n",
    "    'std err': std_err,\n",
    "    't': t_values,\n",
    "    'P>|t|': p_values,\n",
    "    'Durbin-Watson': dw_statistic,\n",
    "    'Jarque-Bera (JB)': jb_statistic,\n",
    "    'Prob(JB)': prob_jb,\n",
    "    'Skew': skew,\n",
    "    'Kurtosis': kurtosis\n",
    "}\n",
    "\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ea64d-6edc-4b37-9ff9-ede937bf1939",
   "metadata": {},
   "source": [
    "### 1.4.1 Lineare Regression ohne Sparkoptimierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15e67860-c100-450b-a82a-8147fc35694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_manual_qr(X, y):\n",
    "    \"\"\"\n",
    "    Fits linear regression using manual QR decomposition.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        Design matrix including intercept\n",
    "    y : ndarray\n",
    "        Target variable vector\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Regression results including coefficients and statistics\n",
    "    float\n",
    "        Computation time in seconds\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Uses Gram-Schmidt QR decomposition\n",
    "    - Computes comprehensive statistics\n",
    "    - Includes timing information\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    Q, R = gram_schmidt(X)\n",
    "    beta = backward_substitution(R, Q.T @ y)\n",
    "\n",
    "    y_pred = np.dot(X, beta) # mit den durch QR berechneten Betas die vorhergesagten y-Werte des linReg Modells bestimmen\n",
    "    residuals = y - y_pred\n",
    "\n",
    "    result = compute_statistics_numpy(X, y, beta, residuals)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    return result, elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f46832-388d-431c-94e7-7158f2545563",
   "metadata": {},
   "source": [
    "### 1.4.2 Optimiert für Spark mit manueller QR Zerlegung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a353e714-0791-4068-a632-ca4b4b1d2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ols_manual2(df):\n",
    "    \"\"\"\n",
    "    Fits distributed OLS regression using manual QR decomposition in Spark.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Spark DataFrame with features and target columns\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        Estimated coefficients\n",
    "    dict\n",
    "        Regression statistics\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Implements distributed QR decomposition\n",
    "    - Handles computation in partitions\n",
    "    - Includes timing information\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Step 1: Calculate combined QR decomposition across partitions\n",
    "    def process_partition(iterator):\n",
    "        X_local, y_local = [], []\n",
    "        for row in iterator:\n",
    "            X_local.append(row.features.toArray())\n",
    "            y_local.append(row.y)\n",
    "\n",
    "        if not X_local:\n",
    "            print(\"Empty partition encountered in process_partition.\")\n",
    "            return [(np.zeros((1, 1)), np.zeros(1))]  # Return a default structure to avoid empty lists\n",
    "\n",
    "        X_local = np.vstack(X_local)\n",
    "        y_local = np.array(y_local)\n",
    "\n",
    "        # Perform local QR decomposition\n",
    "        Q_local, R_local = manual_qr_decomposition(X_local)\n",
    "\n",
    "        # Calculate local Q^T y\n",
    "        Qty_local = np.dot(Q_local.T, y_local)\n",
    "\n",
    "        return [(R_local, Qty_local)]\n",
    "\n",
    "    # Aggregate QR decomposition results\n",
    "    results = df.rdd.mapPartitions(process_partition).filter(lambda x: len(x) > 0).reduce(\n",
    "        lambda a, b: (\n",
    "            a[0] + b[0] if isinstance(a[0], np.ndarray) and isinstance(b[0], np.ndarray) else np.zeros((1, 1)),\n",
    "            a[1] + b[1] if isinstance(a[1], np.ndarray) and isinstance(b[1], np.ndarray) else np.zeros(1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    R_total, Qty_total = results\n",
    "\n",
    "    # Step 2: Final QR on combined R_total\n",
    "    _, R_final = manual_qr_decomposition(R_total)\n",
    "    beta = backward_substitution(R_final, Qty_total)\n",
    "\n",
    "    # Step 3: Distributed calculation of statistics with additional checks\n",
    "    rdd_stats = df.rdd.mapPartitions(lambda iter: [compute_statistics_partition(iter, beta)])\n",
    "    X = np.array(df.select(\"features\").rdd.map(lambda row: row[0].toArray()).collect())  # Or however X is obtained\n",
    "    XtX_inv = np.linalg.inv(np.dot(X.T, X))\n",
    "    y_pred = np.dot(X, beta)  # Predicted values based on beta\n",
    "    residuals = df.select(\"y\").rdd.map(lambda row: row[0]).collect() - y_pred  # Calculate residuals\n",
    "\n",
    "# Pass residuals to aggregate_statistics\n",
    "    stats = aggregate_statistics(rdd_stats, n=df.count(), beta_length=len(beta), XtX_inv=XtX_inv, residuals=residuals, beta=beta)\n",
    "\n",
    "    # Add computation time to stats\n",
    "    computation_time = time.time() - start_time\n",
    "    stats['computation_time'] = computation_time\n",
    "    \n",
    "    return beta, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f984c5e9-2db4-4409-9fdb-7985c8c525d1",
   "metadata": {},
   "source": [
    "### Optimiert für Spark mit Built-In Functions für die QR Zerlegung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff1651dd-4214-4996-b8d9-5fce20fada03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ols_spark(df):\n",
    "    \"\"\"\n",
    "    Fits linear regression using Spark's built-in implementation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Spark DataFrame with features and target columns\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    LinearRegressionModel\n",
    "        Fitted Spark linear regression model\n",
    "    LinearRegressionTrainingSummary\n",
    "        Training summary with model statistics\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Uses Spark's MLlib implementation\n",
    "    - Uses QR decomposition solver\n",
    "    - Provides standard Spark model metrics\n",
    "    \"\"\"\n",
    "    lr = LinearRegression(featuresCol=\"features\", labelCol=\"y\", solver=\"normal\")\n",
    "    model = lr.fit(df)\n",
    "    \n",
    "    # Get the training summary to extract information like R^2, RMSE, etc.\n",
    "    training_summary = model.summary\n",
    "    \n",
    "    return model, training_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4560b59-a830-4be4-a0ab-814ae0cdd1ba",
   "metadata": {},
   "source": [
    "## 1.5) Funktion für Durchführung des Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196e160-68ec-426b-8610-0f8fb5f106ef",
   "metadata": {},
   "source": [
    "### 1.5.1 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b2181d-80dc-43b6-8b31-78799d463b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_summary(beta, statistics, computation_time, X):\n",
    "    \"\"\"\n",
    "    Formats regression results to match statsmodels summary output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    beta : ndarray\n",
    "        Estimated coefficients\n",
    "    statistics : dict\n",
    "        Dictionary of computed statistics\n",
    "    computation_time : float\n",
    "        Model fitting time in seconds\n",
    "    X : ndarray\n",
    "        Design matrix used in the regression\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Formatted summary string\n",
    "    \"\"\"\n",
    "    n_obs = statistics['n_samples']\n",
    "    df_residuals = n_obs - len(beta)\n",
    "    df_model = len(beta) - 1\n",
    "    \n",
    "    # Header\n",
    "    summary = []\n",
    "    summary.append(\"=\" * 78)\n",
    "    summary.append(\"{: ^78}\".format(\"OLS Regression Results\"))\n",
    "    summary.append(\"=\" * 78)\n",
    "    \n",
    "    # Format current date and time\n",
    "    current_time = time.localtime()\n",
    "    formatted_date = time.strftime(\"%a, %d %b %Y\", current_time)\n",
    "    formatted_time = time.strftime(\"%H:%M:%S\", current_time)\n",
    "    \n",
    "    # Left and right columns with exact spacing\n",
    "    summary.append(\"{:<20} {:<12} {:<20} {: >20.3f}\".format(\n",
    "        \"Dep. Variable:\", \"y\",\n",
    "        \"R-squared:\", statistics['r_squared']))\n",
    "    \n",
    "    summary.append(\"{:<20} {:<12} {:<20} {: >20.3f}\".format(\n",
    "        \"Model:\", \"OLS\",\n",
    "        \"Adj. R-squared:\", statistics['Adjusted R-squared']))\n",
    "    \n",
    "    summary.append(\"{:<20} {:<12} {:<20} {: >20.3e}\".format(\n",
    "        \"Method:\", \"Least Squares\",\n",
    "        \"F-statistic:\", statistics['F-statistic']))\n",
    "    \n",
    "    summary.append(\"{:<20} {:<12} {:<20} {: >20.3e}\".format(\n",
    "        \"Date:\", formatted_date,\n",
    "        \"Prob (F-statistic):\", statistics['Prob (F-statistic)']))\n",
    "    \n",
    "    # Log-likelihood (already provided in statistics)\n",
    "    summary.append(\"{:<20} {:<12} {:<20} {: >20.3f}\".format(\n",
    "        \"Time:\", formatted_time,\n",
    "        \"Log-Likelihood:\", statistics['Log-Likelihood']))\n",
    "    \n",
    "    summary.append(\"{:<20} {:<12} {:<20} {: >20.3f}\".format(\n",
    "        \"No. Observations:\", str(n_obs),\n",
    "        \"AIC:\", statistics['AIC']))\n",
    "    \n",
    "    summary.append(\"{:<20} {:<12} {:<20} {: >20.3f}\".format(\n",
    "        \"Df Residuals:\", str(df_residuals),\n",
    "        \"BIC:\", statistics['BIC']))\n",
    "    \n",
    "    summary.append(\"{:<20} {:<12}\".format(\n",
    "        \"Df Model:\", str(df_model)))\n",
    "    \n",
    "    summary.append(\"Covariance Type:            nonrobust\")\n",
    "    \n",
    "    # Parameter estimates table with exact spacing\n",
    "    summary.append(\"=\" * 78)\n",
    "    summary.append(\"{:>16} {:>10} {:>10} {:>10} {:>12} {:>10} {:>10}\".format(\n",
    "        \"\", \"coef\", \"std err\", \"t\", \"P>|t|\", \"[0.025\", \"0.975]\"))\n",
    "    summary.append(\"-\" * 78)\n",
    "    \n",
    "    # Use standard errors, t-stats, p-values, and confidence intervals from statistics\n",
    "    var_names = [\"const\"] + [f\"x{i+1}\" for i in range(len(beta)-1)]\n",
    "    for i, name in enumerate(var_names):\n",
    "        conf_int_lower = beta[i] - 1.96 * statistics['std err'][i]\n",
    "        conf_int_upper = beta[i] + 1.96 * statistics['std err'][i]\n",
    "        summary.append(\"{:>16} {: >9.4f} {: >9.3f} {: >10.3f} {: >11.3f} {: >9.3f} {: >9.3f}\".format(\n",
    "            name,\n",
    "            beta[i],\n",
    "            statistics['std err'][i],\n",
    "            statistics['t'][i],\n",
    "            statistics['P>|t|'][i],\n",
    "            conf_int_lower,\n",
    "            conf_int_upper\n",
    "        ))\n",
    "    \n",
    "    # Diagnostics\n",
    "    summary.append(\"=\" * 78)\n",
    "    summary.append(\"{:<21} {: >10.3f} {:<24} {: >19.3f}\".format(\n",
    "        \"Durbin-Watson:\", statistics['Durbin-Watson'],\n",
    "        \"Jarque-Bera (JB):\", statistics['Jarque-Bera (JB)']))\n",
    "    \n",
    "    summary.append(\"{:<21} {: >10.3f} {:<24} {: >19.3f}\".format(\n",
    "        \"Prob(JB):\", statistics['Prob(JB)'],\n",
    "        \"Skew:\", statistics['Skew']))\n",
    "    \n",
    "    summary.append(\"{:<21} {: >10.3f} {:<24} {: >19.3f}\".format(\n",
    "        \"Kurtosis:\", statistics['Kurtosis'],\n",
    "        \"Cond. No.:\", np.linalg.cond(X)))\n",
    "    \n",
    "    summary.append(\"=\" * 78)\n",
    "    summary.append(\"[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\")\n",
    "    \n",
    "    return \"\\n\".join(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a3f13-0fb2-494f-98d2-137e5fa557bc",
   "metadata": {},
   "source": [
    "### Berechnung für Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67f44301-7434-41a8-bebe-410ba1b9ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark_numpy(n_list, beta_true, p, repetitions=10):\n",
    "    \"\"\"\n",
    "    Runs benchmarking for different implementations of linear regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_list : list\n",
    "        Sample sizes to test\n",
    "    p : int\n",
    "        Number of features\n",
    "    beta_true : ndarray\n",
    "        True coefficients for data generation\n",
    "    repetitions : int, optional\n",
    "        Number of benchmark repetitions, default=10\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Benchmark results including:\n",
    "        - Sample sizes\n",
    "        - Mean and std of computation times\n",
    "        - Mean and std of R-squared values\n",
    "        - Success rates\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Includes error handling\n",
    "    - Prints progress information\n",
    "    - Generates comprehensive summaries\n",
    "    \"\"\"\n",
    "    results = []  # Use a list to accumulate results across sample sizes\n",
    "\n",
    "    for n in n_list:\n",
    "        times = []\n",
    "        r_squared_values = []\n",
    "        print(f\"\\nBenchmarking for n={n:,} samples...\")\n",
    "\n",
    "        for i in range(repetitions):\n",
    "            # Generate synthetic data for each sample size\n",
    "            X = np.hstack([np.ones((n, 1)), np.random.randn(n, p)])  # Add intercept\n",
    "            y = X @ beta_true + np.random.normal(0, 0.1, n)  # Generate y with some noise\n",
    "\n",
    "            # Run the manual QR-based regression and measure time\n",
    "            result, elapsed_time = linear_regression_manual_qr(X, y)\n",
    "            times.append(elapsed_time)\n",
    "            r_squared_values.append(result['r_squared'])\n",
    "\n",
    "        # Compute average computation time and R-squared statistics\n",
    "        avg_time = np.mean(times)\n",
    "        avg_r_squared = np.mean(r_squared_values)\n",
    "        std_time = np.std(times)\n",
    "        std_r_squared = np.std(r_squared_values)\n",
    "\n",
    "        # Prepare the statistics dictionary for format_summary\n",
    "        avg_statistics = {\n",
    "            'n_samples': n,\n",
    "            'SSE': np.sum((y - X @ result['coef']) ** 2),\n",
    "            'r_squared': result['r_squared'],\n",
    "            'Adjusted R-squared': result['Adjusted R-squared'],\n",
    "            'F-statistic': result['F-statistic'],\n",
    "            'Prob (F-statistic)': result['Prob (F-statistic)'],\n",
    "            'Log-Likelihood': result['Log-Likelihood'],\n",
    "            'AIC': result['AIC'],\n",
    "            'BIC': result['BIC'],\n",
    "            'coef': result['coef'],\n",
    "            'std err': result['std err'],\n",
    "            't': result['t'],\n",
    "            'P>|t|': result['P>|t|'],\n",
    "            'Skew': result['Skew'],\n",
    "            'Kurtosis': result['Kurtosis'],\n",
    "            'Durbin-Watson': result['Durbin-Watson'],\n",
    "            'Jarque-Bera (JB)': result['Jarque-Bera (JB)'],\n",
    "            'Prob(JB)': result['Prob(JB)'],\n",
    "            'mse': result['mse']\n",
    "        }\n",
    "\n",
    "        # Print a formatted summary for the last repetition\n",
    "        print(\"\\nSummary for final run:\")\n",
    "        summary_str = format_summary(result['coef'], avg_statistics, avg_time, X)\n",
    "\n",
    "        print(summary_str)\n",
    "\n",
    "        # Append results for this sample size to the results list\n",
    "        results.append({\n",
    "            'n_samples': n,\n",
    "            'n_features': p,\n",
    "            'mean_time': avg_time,\n",
    "            'std_time': std_time,\n",
    "            'mean_r_squared': avg_r_squared,\n",
    "            'std_r_squared': std_r_squared\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nSummary for n={n:,}:\")\n",
    "        print(f\"  Mean time: {avg_time:.2f}s ± {std_time:.2f}s\")\n",
    "        print(f\"  Mean R²: {avg_r_squared:.4f} ± {std_r_squared:.4f}\")\n",
    "\n",
    "    # Return DataFrame with summary of all results\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee49a82-d6f0-4301-a20e-3f03407be25a",
   "metadata": {},
   "source": [
    "### Berechnung für einen festen Wert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4726dfbf-79ed-4be7-87ca-222d8aaa810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark_point(n, p, true_coefficients, repetitions=10):\n",
    "    \"\"\"\n",
    "    Runs benchmarking for different implementations of linear regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Sample size(s) to test\n",
    "    p : int\n",
    "        Number of features\n",
    "    true_coefficients : ndarray\n",
    "        True coefficients for data generation\n",
    "    repetitions : int, optional\n",
    "        Number of benchmark repetitions, default=10\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Benchmark results including:\n",
    "        - Sample sizes\n",
    "        - Mean and std of computation times\n",
    "        - Mean and std of R-squared values\n",
    "        - Success rates\n",
    "    \"\"\"\n",
    "    times = []\n",
    "    r_squares = []\n",
    "    successful_runs = 0\n",
    "\n",
    "    print(f\"\\nBenchmarking n={n:,} samples...\")\n",
    "    \n",
    "    for i in range(repetitions):\n",
    "        try:\n",
    "            # Profile data creation time\n",
    "            start_data_creation = time.time()\n",
    "            df = create_data_spark(n, p, true_coefficients)\n",
    "            end_data_creation = time.time()\n",
    "\n",
    "            # Extract feature matrix X from DataFrame\n",
    "            X = np.array(df.select(\"features\").rdd.map(lambda row: row[0].toArray()).collect())\n",
    "\n",
    "            # Profile model fitting time\n",
    "            start_fit = time.time()\n",
    "            beta, summary = fit_ols_manual2(df)  # Replace with fit_ols_manual if needed\n",
    "            end_fit = time.time()\n",
    "\n",
    "            # Measure total run time\n",
    "            elapsed_time = end_fit - start_data_creation\n",
    "            times.append(elapsed_time)\n",
    "            r_squares.append(summary['r_squared'])\n",
    "            successful_runs += 1\n",
    "            \n",
    "            print(f\"  Run {i+1}: time={elapsed_time:.2f}s, R²={summary['r_squared']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Run {i+1} failed: {str(e)}\")\n",
    "    \n",
    "    if successful_runs > 0:\n",
    "        result = {\n",
    "            'n_samples': n,\n",
    "            'n_features': p,\n",
    "            'mean_time': np.mean(times),\n",
    "            'std_time': np.std(times),\n",
    "            'mean_r_squared': np.mean(r_squares),\n",
    "            'std_r_squared': np.std(r_squares),\n",
    "            'successful_runs': successful_runs\n",
    "        }\n",
    "        print(format_summary(beta, summary, result['mean_time'], X))\n",
    "        print(f\"\\nSummary for n={n:,}:\")\n",
    "        print(f\"  Mean time: {result['mean_time']:.2f}s ± {result['std_time']:.2f}s\")\n",
    "        print(f\"  Mean R²: {result['mean_r_squared']:.4f} ± {result['std_r_squared']:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame([result])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3424ab2-16f9-4cf1-a321-fe79f93a2e96",
   "metadata": {},
   "source": [
    "### Berechnung für Spark Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46854dfe-34a2-4a13-9ce3-e37e71d9c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark_spark(n, p, beta_true, repetitions=10):\n",
    "    \"\"\"\n",
    "    Runs benchmarking for different implementations of linear regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Sample size(s) to test\n",
    "    p : int\n",
    "        Number of features\n",
    "    beta_true : ndarray\n",
    "        True coefficients for data generation\n",
    "    repetitions : int, optional\n",
    "        Number of benchmark repetitions, default=10\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Benchmark results including:\n",
    "        - Sample sizes\n",
    "        - Mean and std of computation times\n",
    "        - Mean and std of R-squared values\n",
    "        - Success rates\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    - Includes error handling\n",
    "    - Prints progress information\n",
    "    - Generates comprehensive summaries\n",
    "    \"\"\"\n",
    "    times = []\n",
    "    r_squares = []\n",
    "    successful_runs = 0\n",
    "    results = []\n",
    "\n",
    "    print(f\"\\nBenchmarking for n={n:,} samples...\")\n",
    "\n",
    "    for i in range(repetitions):\n",
    "        try:\n",
    "            # Generate synthetic data\n",
    "            start_data_creation = time.time()\n",
    "            df = create_data_spark(n, p, beta_true)\n",
    "            end_data_creation = time.time()\n",
    "\n",
    "            # Fit the model\n",
    "            start_fit = time.time()\n",
    "            model, summary = fit_ols_spark(df)\n",
    "            end_fit = time.time()\n",
    "\n",
    "            # Measure total elapsed time\n",
    "            elapsed_time = end_fit - start_data_creation\n",
    "            times.append(elapsed_time)\n",
    "            r_squares.append(summary.r2)\n",
    "            successful_runs += 1\n",
    "\n",
    "            print(f\"  Run {i+1}: time={elapsed_time:.2f}s, R²={summary.r2:.4f}, Adjusted R²={summary.r2adj:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Run {i+1} failed: {str(e)}\")\n",
    "\n",
    "    \n",
    "    if successful_runs > 0:\n",
    "        result = {\n",
    "        'n_samples': n,\n",
    "        'n_features': p,\n",
    "        'mean_time': np.mean(times),\n",
    "        'std_time': np.std(times),\n",
    "        'mean_r_squared': np.mean(r_squares),\n",
    "        'std_r_squared': np.std(r_squares),\n",
    "        'successful_runs': successful_runs\n",
    "    }\n",
    "\n",
    "        print(f\"\\nSummary for n={n:,}:\")\n",
    "        print(f\"  Mean time: {result['mean_time']:.2f}s ± {result['std_time']:.2f}s\")\n",
    "        print(f\"  Mean R²: {result['mean_r_squared']:.4f} ± {result['std_r_squared']:.4f}\")\n",
    "    \n",
    "    return pd.DataFrame([result])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f3e295-03cd-479b-aefc-eb1e577872f8",
   "metadata": {},
   "source": [
    "# 2) Durchführung des Benchmarks und Ausgeben der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09235d19-d83b-489f-8b37-c6069fa456bc",
   "metadata": {},
   "source": [
    "## 2.1) Durchführung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abc3af8e-216f-4022-97c8-93469e34da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [200000, 500000, 1000000, 5000000, 10000000]\n",
    "n_features = 10\n",
    "beta_true = np.random.randn(n_features + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da201d6c-78d5-48d3-8108-e6f372726307",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values2 = [15000000, 20000000, 25000000, 30000000, 35000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3716d95e-0cca-4fb9-8de4-a7729df933d4",
   "metadata": {},
   "source": [
    "### 2.1.1 Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca3874e2-0a3d-4276-a57c-db966351ea4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking for n=200,000 samples...\n",
      "\n",
      "Summary for final run:\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       y            R-squared:                          0.996\n",
      "Model:               OLS          Adj. R-squared:                     0.996\n",
      "Method:              Least Squares F-statistic:                    5.241e+06\n",
      "Date:                Wed, 30 Oct 2024 Prob (F-statistic):             0.000e+00\n",
      "Time:                14:20:42     Log-Likelihood:                176861.927\n",
      "No. Observations:    200000       AIC:                          -353701.853\n",
      "Df Residuals:        199989       BIC:                          -921176.000\n",
      "Df Model:            10          \n",
      "Covariance Type:            nonrobust\n",
      "==============================================================================\n",
      "                       coef    std err          t        P>|t|     [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "           const    3.2920     0.000  14731.398       0.000     3.292     3.292\n",
      "              x1    0.1573     0.000    704.321       0.000     0.157     0.158\n",
      "              x2    0.1358     0.000    608.122       0.000     0.135     0.136\n",
      "              x3    0.8324     0.000   3719.883       0.000     0.832     0.833\n",
      "              x4   -0.1219     0.000   -546.092       0.000    -0.122    -0.122\n",
      "              x5    0.3411     0.000   1526.454       0.000     0.341     0.342\n",
      "              x6   -0.2621     0.000  -1173.660       0.000    -0.262    -0.262\n",
      "              x7   -0.5556     0.000  -2478.844       0.000    -0.556    -0.555\n",
      "              x8    0.7041     0.000   3157.982       0.000     0.704     0.705\n",
      "              x9   -0.3670     0.000  -1640.661       0.000    -0.367    -0.367\n",
      "             x10    0.8697     0.000   3881.485       0.000     0.869     0.870\n",
      "==============================================================================\n",
      "Durbin-Watson:             1.995 Jarque-Bera (JB):                      2.482\n",
      "Prob(JB):                  0.289 Skew:                                  0.009\n",
      "Kurtosis:                  2.998 Cond. No.:                             1.015\n",
      "==============================================================================\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Summary for n=200,000:\n",
      "  Mean time: 0.63s ± 0.68s\n",
      "  Mean R²: 0.9962 ± 0.0000\n",
      "\n",
      "Benchmarking for n=500,000 samples...\n",
      "\n",
      "Summary for final run:\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       y            R-squared:                          0.996\n",
      "Model:               OLS          Adj. R-squared:                     0.996\n",
      "Method:              Least Squares F-statistic:                    1.313e+07\n",
      "Date:                Wed, 30 Oct 2024 Prob (F-statistic):             0.000e+00\n",
      "Time:                14:20:49     Log-Likelihood:                441583.886\n",
      "No. Observations:    500000       AIC:                          -883145.773\n",
      "Df Residuals:        499989       BIC:                         -2301972.960\n",
      "Df Model:            10          \n",
      "Covariance Type:            nonrobust\n",
      "==============================================================================\n",
      "                       coef    std err          t        P>|t|     [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "           const    3.2921     0.000  23267.247       0.000     3.292     3.292\n",
      "              x1    0.1568     0.000   1106.861       0.000     0.157     0.157\n",
      "              x2    0.1360     0.000    961.044       0.000     0.136     0.136\n",
      "              x3    0.8325     0.000   5887.043       0.000     0.832     0.833\n",
      "              x4   -0.1221     0.000   -862.907       0.000    -0.122    -0.122\n",
      "              x5    0.3411     0.000   2406.169       0.000     0.341     0.341\n",
      "              x6   -0.2620     0.000  -1851.187       0.000    -0.262    -0.262\n",
      "              x7   -0.5552     0.000  -3927.772       0.000    -0.556    -0.555\n",
      "              x8    0.7039     0.000   4978.726       0.000     0.704     0.704\n",
      "              x9   -0.3669     0.000  -2596.031       0.000    -0.367    -0.367\n",
      "             x10    0.8696     0.000   6127.642       0.000     0.869     0.870\n",
      "==============================================================================\n",
      "Durbin-Watson:             1.993 Jarque-Bera (JB):                      0.424\n",
      "Prob(JB):                  0.809 Skew:                                 -0.000\n",
      "Kurtosis:                  3.004 Cond. No.:                             1.009\n",
      "==============================================================================\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Summary for n=500,000:\n",
      "  Mean time: 0.48s ± 0.03s\n",
      "  Mean R²: 0.9962 ± 0.0000\n",
      "\n",
      "Benchmarking for n=1,000,000 samples...\n",
      "\n",
      "Summary for final run:\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       y            R-squared:                          0.996\n",
      "Model:               OLS          Adj. R-squared:                     0.996\n",
      "Method:              Least Squares F-statistic:                    2.639e+07\n",
      "Date:                Wed, 30 Oct 2024 Prob (F-statistic):             0.000e+00\n",
      "Time:                14:21:03     Log-Likelihood:                883969.782\n",
      "No. Observations:    1000000      AIC:                         -1767917.564\n",
      "Df Residuals:        999989       BIC:                         -4605675.660\n",
      "Df Model:            10          \n",
      "Covariance Type:            nonrobust\n",
      "==============================================================================\n",
      "                       coef    std err          t        P>|t|     [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "           const    3.2922     0.000  32932.675       0.000     3.292     3.292\n",
      "              x1    0.1567     0.000   1568.463       0.000     0.157     0.157\n",
      "              x2    0.1361     0.000   1362.547       0.000     0.136     0.136\n",
      "              x3    0.8326     0.000   8328.220       0.000     0.832     0.833\n",
      "              x4   -0.1221     0.000  -1222.257       0.000    -0.122    -0.122\n",
      "              x5    0.3411     0.000   3408.447       0.000     0.341     0.341\n",
      "              x6   -0.2621     0.000  -2622.442       0.000    -0.262    -0.262\n",
      "              x7   -0.5552     0.000  -5548.221       0.000    -0.555    -0.555\n",
      "              x8    0.7040     0.000   7037.915       0.000     0.704     0.704\n",
      "              x9   -0.3672     0.000  -3674.238       0.000    -0.367    -0.367\n",
      "             x10    0.8695     0.000   8698.060       0.000     0.869     0.870\n",
      "==============================================================================\n",
      "Durbin-Watson:             1.996 Jarque-Bera (JB):                      6.832\n",
      "Prob(JB):                  0.033 Skew:                                  0.006\n",
      "Kurtosis:                  2.994 Cond. No.:                             1.006\n",
      "==============================================================================\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Summary for n=1,000,000:\n",
      "  Mean time: 0.95s ± 0.11s\n",
      "  Mean R²: 0.9962 ± 0.0000\n",
      "\n",
      "Benchmarking for n=5,000,000 samples...\n",
      "\n",
      "Summary for final run:\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       y            R-squared:                          0.996\n",
      "Model:               OLS          Adj. R-squared:                     0.996\n",
      "Method:              Least Squares F-statistic:                    1.316e+08\n",
      "Date:                Wed, 30 Oct 2024 Prob (F-statistic):             0.000e+00\n",
      "Time:                14:22:14     Log-Likelihood:               4419791.072\n",
      "No. Observations:    5000000      AIC:                         -8839560.145\n",
      "Df Residuals:        4999989      BIC:                        -23028808.803\n",
      "Df Model:            10          \n",
      "Covariance Type:            nonrobust\n",
      "==============================================================================\n",
      "                       coef    std err          t        P>|t|     [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "           const    3.2923     0.000  73641.283       0.000     3.292     3.292\n",
      "              x1    0.1568     0.000   3510.095       0.000     0.157     0.157\n",
      "              x2    0.1360     0.000   3040.507       0.000     0.136     0.136\n",
      "              x3    0.8326     0.000  18612.651       0.000     0.832     0.833\n",
      "              x4   -0.1222     0.000  -2732.702       0.000    -0.122    -0.122\n",
      "              x5    0.3411     0.000   7631.490       0.000     0.341     0.341\n",
      "              x6   -0.2621     0.000  -5860.673       0.000    -0.262    -0.262\n",
      "              x7   -0.5554     0.000 -12423.486       0.000    -0.555    -0.555\n",
      "              x8    0.7039     0.000  15748.721       0.000     0.704     0.704\n",
      "              x9   -0.3671     0.000  -8207.742       0.000    -0.367    -0.367\n",
      "             x10    0.8696     0.000  19451.259       0.000     0.869     0.870\n",
      "==============================================================================\n",
      "Durbin-Watson:             1.999 Jarque-Bera (JB):                      0.382\n",
      "Prob(JB):                  0.826 Skew:                                  0.001\n",
      "Kurtosis:                  3.000 Cond. No.:                             1.003\n",
      "==============================================================================\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Summary for n=5,000,000:\n",
      "  Mean time: 4.79s ± 0.35s\n",
      "  Mean R²: 0.9962 ± 0.0000\n",
      "\n",
      "Benchmarking for n=10,000,000 samples...\n",
      "\n",
      "Summary for final run:\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       y            R-squared:                          0.996\n",
      "Model:               OLS          Adj. R-squared:                     0.996\n",
      "Method:              Least Squares F-statistic:                    2.631e+08\n",
      "Date:                Wed, 30 Oct 2024 Prob (F-statistic):             0.000e+00\n",
      "Time:                14:24:27     Log-Likelihood:               8836839.320\n",
      "No. Observations:    10000000     AIC:                        -17673656.641\n",
      "Df Residuals:        9999989      BIC:                        -46052283.006\n",
      "Df Model:            10          \n",
      "Covariance Type:            nonrobust\n",
      "==============================================================================\n",
      "                       coef    std err          t        P>|t|     [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "           const    3.2924     0.000 104118.021       0.000     3.292     3.292\n",
      "              x1    0.1569     0.000   4959.734       0.000     0.157     0.157\n",
      "              x2    0.1360     0.000   4300.013       0.000     0.136     0.136\n",
      "              x3    0.8326     0.000  26319.564       0.000     0.833     0.833\n",
      "              x4   -0.1221     0.000  -3861.786       0.000    -0.122    -0.122\n",
      "              x5    0.3412     0.000  10786.489       0.000     0.341     0.341\n",
      "              x6   -0.2620     0.000  -8285.897       0.000    -0.262    -0.262\n",
      "              x7   -0.5553     0.000 -17559.863       0.000    -0.555    -0.555\n",
      "              x8    0.7040     0.000  22267.126       0.000     0.704     0.704\n",
      "              x9   -0.3671     0.000 -11613.093       0.000    -0.367    -0.367\n",
      "             x10    0.8696     0.000  27492.396       0.000     0.869     0.870\n",
      "==============================================================================\n",
      "Durbin-Watson:             1.999 Jarque-Bera (JB):                     11.140\n",
      "Prob(JB):                  0.004 Skew:                                  0.002\n",
      "Kurtosis:                  2.997 Cond. No.:                             1.002\n",
      "==============================================================================\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Summary for n=10,000,000:\n",
      "  Mean time: 8.72s ± 0.22s\n",
      "  Mean R²: 0.9962 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "results_numpy = run_benchmark_numpy(n_list=n_values, beta_true=beta_true, p=n_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d3ba12d-a140-4aad-a7ce-39085b57220a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>std_time</th>\n",
       "      <th>mean_r_squared</th>\n",
       "      <th>std_r_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.628908</td>\n",
       "      <td>0.675015</td>\n",
       "      <td>0.996210</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.482134</td>\n",
       "      <td>0.031184</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.952605</td>\n",
       "      <td>0.112846</td>\n",
       "      <td>0.996215</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000000</td>\n",
       "      <td>10</td>\n",
       "      <td>4.790818</td>\n",
       "      <td>0.350156</td>\n",
       "      <td>0.996212</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>8.715023</td>\n",
       "      <td>0.215088</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_samples  n_features  mean_time  std_time  mean_r_squared  std_r_squared\n",
       "0     200000          10   0.628908  0.675015        0.996210       0.000012\n",
       "1     500000          10   0.482134  0.031184        0.996214       0.000010\n",
       "2    1000000          10   0.952605  0.112846        0.996215       0.000009\n",
       "3    5000000          10   4.790818  0.350156        0.996212       0.000004\n",
       "4   10000000          10   8.715023  0.215088        0.996214       0.000002"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "021f6785-85a3-4017-864c-451b67327a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking for n=15,000,000 samples...\n",
      "\n",
      "Summary for final run:\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       y            R-squared:                          0.996\n",
      "Model:               OLS          Adj. R-squared:                     0.996\n",
      "Method:              Least Squares F-statistic:                    3.949e+08\n",
      "Date:                Wed, 30 Oct 2024 Prob (F-statistic):             0.000e+00\n",
      "Time:                14:27:44     Log-Likelihood:              13255065.561\n",
      "No. Observations:    15000000     AIC:                        -26510109.123\n",
      "Df Residuals:        14999989     BIC:                        -69078116.360\n",
      "Df Model:            10          \n",
      "Covariance Type:            nonrobust\n",
      "==============================================================================\n",
      "                       coef    std err          t        P>|t|     [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "           const    3.2924     0.000 127516.145       0.000     3.292     3.292\n",
      "              x1    0.1569     0.000   6079.284       0.000     0.157     0.157\n",
      "              x2    0.1361     0.000   5268.052       0.000     0.136     0.136\n",
      "              x3    0.8326     0.000  32253.367       0.000     0.833     0.833\n",
      "              x4   -0.1222     0.000  -4733.780       0.000    -0.122    -0.122\n",
      "              x5    0.3411     0.000  13216.244       0.000     0.341     0.341\n",
      "              x6   -0.2620     0.000 -10149.922       0.000    -0.262    -0.262\n",
      "              x7   -0.5554     0.000 -21507.818       0.000    -0.555    -0.555\n",
      "              x8    0.7040     0.000  27265.755       0.000     0.704     0.704\n",
      "              x9   -0.3671     0.000 -14223.878       0.000    -0.367    -0.367\n",
      "             x10    0.8696     0.000  33674.016       0.000     0.870     0.870\n",
      "==============================================================================\n",
      "Durbin-Watson:             2.000 Jarque-Bera (JB):                      4.017\n",
      "Prob(JB):                  0.134 Skew:                                  0.001\n",
      "Kurtosis:                  2.998 Cond. No.:                             1.002\n",
      "==============================================================================\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Summary for n=15,000,000:\n",
      "  Mean time: 12.49s ± 0.12s\n",
      "  Mean R²: 0.9962 ± 0.0000\n",
      "\n",
      "Benchmarking for n=20,000,000 samples...\n",
      "\n",
      "Summary for final run:\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       y            R-squared:                          0.996\n",
      "Model:               OLS          Adj. R-squared:                     0.996\n",
      "Method:              Least Squares F-statistic:                    5.263e+08\n",
      "Date:                Wed, 30 Oct 2024 Prob (F-statistic):             0.000e+00\n",
      "Time:                14:32:05     Log-Likelihood:              17672460.795\n",
      "No. Observations:    20000000     AIC:                        -35344899.589\n",
      "Df Residuals:        19999989     BIC:                        -92102288.994\n",
      "Df Model:            10          \n",
      "Covariance Type:            nonrobust\n",
      "==============================================================================\n",
      "                       coef    std err          t        P>|t|     [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "           const    3.2924     0.000 147235.869       0.000     3.292     3.292\n",
      "              x1    0.1569     0.000   7015.952       0.000     0.157     0.157\n",
      "              x2    0.1360     0.000   6083.521       0.000     0.136     0.136\n",
      "              x3    0.8326     0.000  37232.702       0.000     0.833     0.833\n",
      "              x4   -0.1222     0.000  -5464.859       0.000    -0.122    -0.122\n",
      "              x5    0.3412     0.000  15254.967       0.000     0.341     0.341\n",
      "              x6   -0.2620     0.000 -11718.114       0.000    -0.262    -0.262\n",
      "              x7   -0.5554     0.000 -24837.676       0.000    -0.555    -0.555\n",
      "              x8    0.7040     0.000  31484.062       0.000     0.704     0.704\n",
      "              x9   -0.3671     0.000 -16416.578       0.000    -0.367    -0.367\n",
      "             x10    0.8696     0.000  38892.065       0.000     0.870     0.870\n",
      "==============================================================================\n",
      "Durbin-Watson:             2.000 Jarque-Bera (JB):                      0.142\n",
      "Prob(JB):                  0.932 Skew:                                 -0.000\n",
      "Kurtosis:                  3.000 Cond. No.:                             1.001\n",
      "==============================================================================\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Summary for n=20,000,000:\n",
      "  Mean time: 16.34s ± 0.23s\n",
      "  Mean R²: 0.9962 ± 0.0000\n",
      "\n",
      "Benchmarking for n=25,000,000 samples...\n",
      "\n",
      "Summary for final run:\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       y            R-squared:                          0.996\n",
      "Model:               OLS          Adj. R-squared:                     0.996\n",
      "Method:              Least Squares F-statistic:                    6.575e+08\n",
      "Date:                Wed, 30 Oct 2024 Prob (F-statistic):             0.000e+00\n",
      "Time:                14:37:24     Log-Likelihood:              22087721.610\n",
      "No. Observations:    25000000     AIC:                        -44175421.220\n",
      "Df Residuals:        24999989     BIC:                       -115122193.502\n",
      "Df Model:            10          \n",
      "Covariance Type:            nonrobust\n",
      "==============================================================================\n",
      "                       coef    std err          t        P>|t|     [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "           const    3.2923     0.000 164594.095       0.000     3.292     3.292\n",
      "              x1    0.1569     0.000   7844.620       0.000     0.157     0.157\n",
      "              x2    0.1360     0.000   6800.155       0.000     0.136     0.136\n",
      "              x3    0.8326     0.000  41625.678       0.000     0.833     0.833\n",
      "              x4   -0.1222     0.000  -6107.926       0.000    -0.122    -0.122\n",
      "              x5    0.3411     0.000  17049.624       0.000     0.341     0.341\n",
      "              x6   -0.2621     0.000 -13099.942       0.000    -0.262    -0.262\n",
      "              x7   -0.5553     0.000 -27760.859       0.000    -0.555    -0.555\n",
      "              x8    0.7040     0.000  35193.942       0.000     0.704     0.704\n",
      "              x9   -0.3671     0.000 -18351.584       0.000    -0.367    -0.367\n",
      "             x10    0.8696     0.000  43472.347       0.000     0.870     0.870\n",
      "==============================================================================\n",
      "Durbin-Watson:             2.000 Jarque-Bera (JB):                      3.705\n",
      "Prob(JB):                  0.157 Skew:                                  0.001\n",
      "Kurtosis:                  3.001 Cond. No.:                             1.001\n",
      "==============================================================================\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Summary for n=25,000,000:\n",
      "  Mean time: 19.80s ± 0.14s\n",
      "  Mean R²: 0.9962 ± 0.0000\n",
      "\n",
      "Benchmarking for n=30,000,000 samples...\n",
      "\n",
      "Summary for final run:\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       y            R-squared:                          0.996\n",
      "Model:               OLS          Adj. R-squared:                     0.996\n",
      "Method:              Least Squares F-statistic:                    7.896e+08\n",
      "Date:                Wed, 30 Oct 2024 Prob (F-statistic):             0.000e+00\n",
      "Time:                14:43:46     Log-Likelihood:              26509592.091\n",
      "No. Observations:    30000000     AIC:                        -53019162.183\n",
      "Df Residuals:        29999989     BIC:                       -138155317.791\n",
      "Df Model:            10          \n",
      "Covariance Type:            nonrobust\n",
      "==============================================================================\n",
      "                       coef    std err          t        P>|t|     [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "           const    3.2924     0.000 180331.400       0.000     3.292     3.292\n",
      "              x1    0.1569     0.000   8594.430       0.000     0.157     0.157\n",
      "              x2    0.1360     0.000   7453.238       0.000     0.136     0.136\n",
      "              x3    0.8326     0.000  45616.005       0.000     0.833     0.833\n",
      "              x4   -0.1222     0.000  -6693.886       0.000    -0.122    -0.122\n",
      "              x5    0.3412     0.000  18686.925       0.000     0.341     0.341\n",
      "              x6   -0.2620     0.000 -14353.082       0.000    -0.262    -0.262\n",
      "              x7   -0.5553     0.000 -30409.094       0.000    -0.555    -0.555\n",
      "              x8    0.7039     0.000  38551.392       0.000     0.704     0.704\n",
      "              x9   -0.3671     0.000 -20106.031       0.000    -0.367    -0.367\n",
      "             x10    0.8695     0.000  47633.381       0.000     0.870     0.870\n",
      "==============================================================================\n",
      "Durbin-Watson:             1.999 Jarque-Bera (JB):                      2.041\n",
      "Prob(JB):                  0.360 Skew:                                  0.001\n",
      "Kurtosis:                  3.001 Cond. No.:                             1.001\n",
      "==============================================================================\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Summary for n=30,000,000:\n",
      "  Mean time: 23.79s ± 0.26s\n",
      "  Mean R²: 0.9962 ± 0.0000\n",
      "\n",
      "Benchmarking for n=35,000,000 samples...\n",
      "\n",
      "Summary for final run:\n",
      "==============================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       y            R-squared:                          0.996\n",
      "Model:               OLS          Adj. R-squared:                     0.996\n",
      "Method:              Least Squares F-statistic:                    9.204e+08\n",
      "Date:                Wed, 30 Oct 2024 Prob (F-statistic):             0.000e+00\n",
      "Time:                14:51:25     Log-Likelihood:              30922836.918\n",
      "No. Observations:    35000000     AIC:                        -61845651.836\n",
      "Df Residuals:        34999989     BIC:                       -161171191.081\n",
      "Df Model:            10          \n",
      "Covariance Type:            nonrobust\n",
      "==============================================================================\n",
      "                       coef    std err          t        P>|t|     [0.025     0.975]\n",
      "------------------------------------------------------------------------------\n",
      "           const    3.2924     0.000 194752.267       0.000     3.292     3.292\n",
      "              x1    0.1569     0.000   9284.490       0.000     0.157     0.157\n",
      "              x2    0.1361     0.000   8047.203       0.000     0.136     0.136\n",
      "              x3    0.8326     0.000  49252.061       0.000     0.833     0.833\n",
      "              x4   -0.1222     0.000  -7227.838       0.000    -0.122    -0.122\n",
      "              x5    0.3412     0.000  20180.181       0.000     0.341     0.341\n",
      "              x6   -0.2621     0.000 -15501.804       0.000    -0.262    -0.262\n",
      "              x7   -0.5554     0.000 -32848.210       0.000    -0.555    -0.555\n",
      "              x8    0.7039     0.000  41639.774       0.000     0.704     0.704\n",
      "              x9   -0.3671     0.000 -21714.071       0.000    -0.367    -0.367\n",
      "             x10    0.8696     0.000  51435.584       0.000     0.870     0.870\n",
      "==============================================================================\n",
      "Durbin-Watson:             2.000 Jarque-Bera (JB):                      4.092\n",
      "Prob(JB):                  0.129 Skew:                                  0.001\n",
      "Kurtosis:                  3.001 Cond. No.:                             1.001\n",
      "==============================================================================\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Summary for n=35,000,000:\n",
      "  Mean time: 30.13s ± 0.87s\n",
      "  Mean R²: 0.9962 ± 0.0000\n"
     ]
    }
   ],
   "source": [
    "results_numpy2 = run_benchmark_numpy(n_list=n_values2, beta_true=beta_true, p=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2858e181-99ef-419b-9e47-ac8f7dee1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_numpy_df = pd.concat([results_numpy, results_numpy2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68259486-0220-4798-992c-7aa26fc4b030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_features</th>\n",
       "      <th>mean_time</th>\n",
       "      <th>std_time</th>\n",
       "      <th>mean_r_squared</th>\n",
       "      <th>std_r_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.628908</td>\n",
       "      <td>0.675015</td>\n",
       "      <td>0.996210</td>\n",
       "      <td>1.154623e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.482134</td>\n",
       "      <td>0.031184</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>1.025484e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.952605</td>\n",
       "      <td>0.112846</td>\n",
       "      <td>0.996215</td>\n",
       "      <td>9.006029e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000000</td>\n",
       "      <td>10</td>\n",
       "      <td>4.790818</td>\n",
       "      <td>0.350156</td>\n",
       "      <td>0.996212</td>\n",
       "      <td>3.671750e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000000</td>\n",
       "      <td>10</td>\n",
       "      <td>8.715023</td>\n",
       "      <td>0.215088</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>1.577912e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15000000</td>\n",
       "      <td>10</td>\n",
       "      <td>12.493335</td>\n",
       "      <td>0.124730</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>2.164683e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20000000</td>\n",
       "      <td>10</td>\n",
       "      <td>16.336071</td>\n",
       "      <td>0.228270</td>\n",
       "      <td>0.996215</td>\n",
       "      <td>2.053358e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25000000</td>\n",
       "      <td>10</td>\n",
       "      <td>19.804174</td>\n",
       "      <td>0.144288</td>\n",
       "      <td>0.996213</td>\n",
       "      <td>1.766141e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30000000</td>\n",
       "      <td>10</td>\n",
       "      <td>23.787051</td>\n",
       "      <td>0.263583</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>1.898277e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35000000</td>\n",
       "      <td>10</td>\n",
       "      <td>30.125023</td>\n",
       "      <td>0.865177</td>\n",
       "      <td>0.996213</td>\n",
       "      <td>9.051791e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_samples  n_features  mean_time  std_time  mean_r_squared  std_r_squared\n",
       "0     200000          10   0.628908  0.675015        0.996210   1.154623e-05\n",
       "1     500000          10   0.482134  0.031184        0.996214   1.025484e-05\n",
       "2    1000000          10   0.952605  0.112846        0.996215   9.006029e-06\n",
       "3    5000000          10   4.790818  0.350156        0.996212   3.671750e-06\n",
       "4   10000000          10   8.715023  0.215088        0.996214   1.577912e-06\n",
       "5   15000000          10  12.493335  0.124730        0.996214   2.164683e-06\n",
       "6   20000000          10  16.336071  0.228270        0.996215   2.053358e-06\n",
       "7   25000000          10  19.804174  0.144288        0.996213   1.766141e-06\n",
       "8   30000000          10  23.787051  0.263583        0.996214   1.898277e-06\n",
       "9   35000000          10  30.125023  0.865177        0.996213   9.051791e-07"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_numpy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26997485-2f3b-4dd1-95cc-5efb1c860c6a",
   "metadata": {},
   "source": [
    "### Benchmark Spark mit manueller QR-Zerlegung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de869ab9-65a4-4416-950d-aa99543a5bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking n=200,000 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 1: time=18.89s, R²=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Run 2: time=10.76s, R²=0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "results_point = []\n",
    "results_point = [run_benchmark_point(n=n, p=n_features, true_coefficients=beta_true) for n in n_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf06ddf-5812-485a-8ad3-f742ae257e5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_point2 = [run_benchmark_point(n=n, p=n_features, true_coefficients=beta_true) for n in n_values2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60124b28-336d-4cea-899d-a25a9d62e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_point_df = pd.concat(results_point , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88059a25-51b6-401a-9dc6-50d0c1c0886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_point_df2 = pd.concat(results_point2, ignore_index=True)\n",
    "results_point_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff87d300-71a8-434d-8885-42661b4477fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_point_final =  pd.concat([results_point_df, results_point_df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce5a8c-2bb1-43d2-95bf-7e78729ef6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_point_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38eab9-100f-40ec-86c3-3ec84a177118",
   "metadata": {},
   "source": [
    "### Benchmark Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ea3fb-b1e3-4230-8a12-45293bcdf20b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_spark = []\n",
    "results_spark = [run_benchmark_spark(n=n, p=n_features, beta_true=beta_true) for n in n_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34d72e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_spark2 = [run_benchmark_spark(n=n, p=n_features, beta_true=beta_true) for n in n_values2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b454784-8787-4264-8e7d-364aa14eeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_spark_df = pd.concat(results_spark, ignore_index=True)\n",
    "results_spark_df2 = pd.concat(results_spark2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04b047-0cb9-412c-bae8-198a0ea8217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_spark_final =  pd.concat([results_spark_df, results_spark_df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9808270a-b03c-4618-a5b7-016536fa9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_spark_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ba8cd-e4cd-43f1-ae36-a039696ce95a",
   "metadata": {},
   "source": [
    "## 2.2) Ausgeben der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5688e6e-9dfa-4ce8-903e-01d61b598899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_info(dataframes, labels=None):\n",
    "    \"\"\"\n",
    "    Extracts and compares R² values and computation times from multiple DataFrames,\n",
    "    structured for easier comparison between approaches.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframes : list of pd.DataFrame\n",
    "        List of DataFrames containing benchmarking results with columns 'n_samples', \n",
    "        'n_features', 'mean_time', and 'mean_r_squared'.\n",
    "    \n",
    "    labels : list of str, optional\n",
    "        List of labels for each DataFrame to identify the source/approach (default is None).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Combined DataFrame with columns 'n_samples', 'n_features', and the mean R² values \n",
    "        and computation times for each approach in separate columns, structured for \n",
    "        side-by-side comparison.\n",
    "    \"\"\"\n",
    "    if labels and len(labels) != len(dataframes):\n",
    "        raise ValueError(\"Length of labels must match length of dataframes\")\n",
    "\n",
    "    # Start with the first dataframe and rename columns for merging\n",
    "    merged_df = dataframes[0].rename(columns={'mean_time': f'{labels[0]}_mean_time', \n",
    "                                              'mean_r_squared': f'{labels[0]}_mean_r_squared'})\n",
    "    \n",
    "    # Merge each subsequent dataframe\n",
    "    for i, df in enumerate(dataframes[1:], start=1):\n",
    "        label = labels[i]\n",
    "        df = df.rename(columns={'mean_time': f'{label}_mean_time', \n",
    "                                'mean_r_squared': f'{label}_mean_r_squared'})\n",
    "        merged_df = pd.merge(merged_df, df[['n_samples', 'n_features', f'{label}_mean_time', f'{label}_mean_r_squared']],\n",
    "                             on=['n_samples', 'n_features'], how='outer')\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e1f5e-2563-48cc-afc7-fe9b05c7c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [results_numpy_df, results_point_final, results_spark_final]\n",
    "labels = [\"Numpy\", \"Spark and manual QR decomposition\", \"Spark Linear Regressions\"]\n",
    "\n",
    "# Extract and compare information\n",
    "comparison_df = extract_info(dataframes, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76fad2-18bf-496b-a8a3-ba65ce3c108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58b5098-64e9-4e05-956a-0605c8884113",
   "metadata": {},
   "source": [
    "## 2.3) Plotten der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a3738-4d09-4794-95fd-7edeb2bebeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_benchmark_results(n_values, avg_times, std_times):\n",
    "    \"\"\"\n",
    "    Plots benchmark results of computation times for a QR decomposition-based regression model \n",
    "    across varying sample sizes, displaying mean computation time with error bars representing \n",
    "    standard deviation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_values : list\n",
    "        List of sample sizes (number of observations) for which benchmarks were performed.\n",
    "    avg_times : list\n",
    "        List of average computation times (in seconds) corresponding to each sample size in n_values.\n",
    "    std_times : list\n",
    "        List of standard deviations of computation times (in seconds) for each sample size in n_values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        The function directly displays a plot, with no return value.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - The plot uses a logarithmic scale on both axes to improve visibility of differences across a range of sample sizes.\n",
    "    - Error bars represent the standard deviation of computation times, offering a visual indication of variability.\n",
    "    - Plot labels, legend, and title are set in English.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.errorbar(n_values, avg_times, yerr=std_times, fmt='o', ecolor='r', capsize=5,\n",
    "                 label='Average Computation Time with Standard Deviation', linestyle='None')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Number of Observations (n)')\n",
    "    plt.ylabel('Computation Time (s)')\n",
    "    plt.title('Computation Time of QR Decomposition-Based Regression for Increasing n')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94435955-82ec-413c-9038-70bca7e4347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmark_results(results_numpy_df[\"n_samples\"], results_numpy_df[\"mean_time\"], results_numpy_df[\"std_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f16519-abac-4883-8ab2-2b095325bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmark_results(results_point_final[\"n_samples\"], results_point_final[\"mean_time\"], results_point_final[\"std_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eca945-d502-4e9b-9968-51e31131a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_point_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5b49a-5d8e-452d-b2ad-2737adc4155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_spark_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dd5e0d-6540-44d4-9e05-cad1be352128",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmark_results(results_spark_final[\"n_samples\"], results_spark_final[\"mean_time\"], results_spark_final[\"std_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10c315-79d4-4ead-a165-3b30af59089a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f86e1f-6d1b-46ab-905e-462090b9bd19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
